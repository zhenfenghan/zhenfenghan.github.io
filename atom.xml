<?xml version="1.0" encoding="utf-8"?>
<feed xmlns="http://www.w3.org/2005/Atom">
  <title>Will&#39;s Blog</title>
  <icon>https://www.gravatar.com/avatar/7c8ece4bce7f5caa1330b25979808087</icon>
  <subtitle>愿意探索生活的更多可能性</subtitle>
  <link href="/atom.xml" rel="self"/>
  
  <link href="https://zhenfenghan.github.io/"/>
  <updated>2018-07-17T03:28:10.387Z</updated>
  <id>https://zhenfenghan.github.io/</id>
  
  <author>
    <name>Will Han</name>
    <email>zhfhan@foxmail.com</email>
  </author>
  
  <generator uri="http://hexo.io/">Hexo</generator>
  
  <entry>
    <title>数据科学可以解决什么问题？</title>
    <link href="https://zhenfenghan.github.io/2018/07/17/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    <id>https://zhenfenghan.github.io/2018/07/17/数据科学/</id>
    <published>2018-07-17T02:01:11.000Z</published>
    <updated>2018-07-17T03:28:10.387Z</updated>
    
    <content type="html"><![CDATA[<p><div align="center"><br><img src="http://linhui.org/images/Jokes/jokeBayes.png" alt=""><br></div></p><h3 id="前提要求"><a href="#前提要求" class="headerlink" title="前提要求"></a>前提要求</h3><p>数据科学不是万能药，数据科学家也不是魔术师，有些问题我们无法用数据科学解决，最好在一开始就对问题做出判断，对于那些无法解决的问题，诚实的告诉对方并解释原因，那我们对问题有什么要求呢？<br><a id="more"></a><br><strong>1.  你的问题需要尽可能具体</strong></p><pre><code>来看两个例子：*   问题1: 如何提高产品销售量？*   问题2: 今年年初推出的新促销手段是不是提高了先锋先玉696玉米种子在西南地区的销售量？比较上面这两个问题，大家是不是很快能发现它们的差别？问题1从语法上是个正确的问题，但从解决的角度，并不是一个能够用分析给出答案的问题。为什么？因为问题太泛了，根本无从定义该问题背后的自变量和应变量。而问题2就是一个恰当的问题。从分析的角度，应变量很明显是“先锋先玉696玉米种子在西南地区的销售量”，感兴趣的自变量是“今年年初推出的新促销手段”，我们想要研究的就是这两者之间的关系。从这里开始再去寻找其它变量，这样就慢慢的进入分析流程了。当然，问题具体不代表就能够回答。比如我曾经遇到一个很具体的供应链问题，问的是针对某一个特定产品在特定区域的库存该是多少。这个问题为什么无法回答呢？这个项目一开始我通过多元自适应回归样条（MARS）模型以为找到了一个合理的答案，但到项目的最后才发现，他们给我的供应相关的数据极其不准确，很多地区的供应量都只是估计。这是我从业生涯中的一次教训，这告诉我们下面将要提到的一点。</code></pre><p><strong>2.  你要有和问题相关的必要数据</strong></p><pre><code>巧妇难为无米之炊，这老古人的话放在那里时刻闪闪发光。艺术源于生活，所以你首先得要有数据，之所以数据科学会火也是因为计算机的发展，使数据的收集更容易。上面提到的供给问题就是一个很好的例子，没有相对准确的数据，之后任何模型都没有意义。当然，任何数据都是存在误差的，但是误差必须在一定范围内。尤其是感兴趣的自变量（如之前问题2里的“新促销手段”相关的数据）和应变量（“先锋先玉696玉米种子在西南地区的销售量”），如果这些必要的变量有很大缺失，或者不准确的话，模型是无法发挥作用的。再如，你要预测某个产品的消费者中谁最可能在接下来的3个月内购买该产品。要解决这个问题，你需要有目标消费者群体历史购买行为的信息：上一次购买的时间，消费量，优惠券使用情况等等。如果你仅仅知道这些客户的银行卡号，身份证号，出生月份之类的信息是不会对你的预测有任何帮助的。很多时候数据的质量比数量重要，但数量也是不容忽视的。在能保证数据质量的前提下，数量越多越好。样本量越大，你能够回答的问题也就更细，且模型发现的置信度也更高。如果你有一个具体合理的问题，有足够大，质量合理的相关数据集，那么恭喜你，可以开始玩数据科学啦！</code></pre><h3 id="问题种类"><a href="#问题种类" class="headerlink" title="问题种类"></a>问题种类</h3><p>很多数据科学的书籍都从技术的角度对各种模型分类。比如有监督模型和无监督模型，线性模型和非线性模型，参数模型和参数模型等等。这里我们换而使用之前提到的“问题导向”的思维方式，对数据科学回答的问题进行分类，然后介绍哪些模型可以用于回答相应类别的问题，希望这些分组能在你面对自己的问题时帮助思考。</p><p><strong>1.  比较</strong></p><pre><code>第一类常见的问题是比较组之间不同的问题。常见的句式是：A在某方面是不是比B好？或者多者比较：A、B、C之间在某方面有没有差别？下面是一些问题的例子：<figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-<span class="ruby"> 参与促销活动和没有参与促销活动消费者购买量有差异么？</span></span><br><span class="line"><span class="ruby">- 男性是不是比女性更倾向于购买我们的产品？</span></span><br><span class="line"><span class="ruby">- 用户满意度在不同商业区是不是有不同？</span></span><br><span class="line"><span class="ruby">- 服用某种药物的老鼠比没有服用药物的老鼠体重增长的是否更快？</span></span><br><span class="line"><span class="ruby">- 携带某种基因的大豆是不是比普通大豆产油量高？</span></span><br></pre></td></tr></table></figure>对于这类数据，通常从各组观测的基本统计量和可视化开始初步探索数据。在对数据分布和组之间的差异有个初步直观了解之后，通过统计检验测试组间是否在感兴趣的变量上有显著不同。处理这类问题常用的是经典统计推断：开方检验，t检验和方差分析。放在贝叶斯框架下也有一种比较组间不同的方法。如果因子增加，结构变得复杂（如在生物医药领域的复杂实验设计有随机效应因子），则需要使用更加复杂的混合效应模型。</code></pre><p><strong>2.  描述</strong></p><pre><code>在分析中不可避免的要描述数据。比如聚类问题。当你通过算法找到不同的样本分类后，就需要对类进行定义，这要通过比较各类中变量的描述统计量得到。常用的描述问题有：<figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-<span class="ruby"> 样本中家庭年观测的收入是不是无偏的？</span></span><br><span class="line"><span class="ruby">- 某产品在不同区域的月销售量均值／方差是多少？</span></span><br><span class="line"><span class="ruby">- 变量的量级差异大么？（决定是否需要对数据标准化）</span></span><br><span class="line"><span class="ruby">- 模型中的预测变量观测缺失情况如何？</span></span><br><span class="line"><span class="ruby">- 问卷调查回复者的年龄分布范围是多少？</span></span><br></pre></td></tr></table></figure>这类数据描述常用于检查数据，找到合适的数据预处理方法，以及拟合模型后对结果的分析和展示。</code></pre><p><strong>3.  聚类</strong></p><pre><code>聚类是一个极其常见的问题，其通常和判别联系在一起。聚类模型回答的问题是：<figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-<span class="ruby"> 哪些消费者有相似的产品偏好？（市场营销）</span></span><br><span class="line"><span class="ruby">- 哪些打印机损坏的模式相同？（质量控制）</span></span><br><span class="line"><span class="ruby">- 公司员工在对公司评价上可以分为几类？（人力资源）</span></span><br><span class="line"><span class="ruby">- 哪些词更经常同时出现？（自然语义处理）</span></span><br><span class="line"><span class="ruby">- 哪些文档可能有相似的主题？（自然语义处理）</span></span><br></pre></td></tr></table></figure>聚类是无监督分析。</code></pre><p><strong>4.  判别</strong></p><pre><code>判别是另外一个经典的分析问题。通常用类别已知的样本作为训练集拟合判别器，然后用训练好的判别器预测新样本的类别。下面是一些关于判别的问题：<figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br></pre></td><td class="code"><pre><span class="line">-<span class="ruby"> 哪些新客户最有可能转化（购买）？</span></span><br><span class="line"><span class="ruby">- 当前的压力度数是正常的么？</span></span><br><span class="line"><span class="ruby">- 某贷款人有不还款的风险么？</span></span><br><span class="line"><span class="ruby">- 这个消费者还可能喜欢什么产品？</span></span><br><span class="line"><span class="ruby">- 这本书的作者可能是谁？</span></span><br><span class="line"><span class="ruby">- 这封邮件是不是垃圾邮件？</span></span><br></pre></td></tr></table></figure>关于判别的模型有数百种，在实践中我们其实不必要尝试所有的模型而只要拟合其中几种在大部分情况下表现最好的模型即可。我们在后面判别的章节还会介绍。</code></pre><p><strong>5.  回归</strong></p><pre><code>当你感兴趣的量是一个数值而非类别时，通常就是一个回归问题。比如：<figure class="highlight haml"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br></pre></td><td class="code"><pre><span class="line">-<span class="ruby"> 明天的气温可能会是多少？</span></span><br><span class="line"><span class="ruby">- 公司今年第<span class="number">4</span>季度的销售额会是多少？</span></span><br><span class="line"><span class="ruby">- 某品牌打印机明年上半年在北京市的销量会是多少？</span></span><br><span class="line"><span class="ruby">- 该引擎还能工作多久？</span></span><br><span class="line"><span class="ruby">- 这次活动中需要准备多少啤酒？</span></span><br></pre></td></tr></table></figure>通常情况下，回归能够给出一个数值答案。回归通常解决“…是多少？”这样的问题。在有些时候模型给出的负数结果可能需要解释为0，或者有小数点的结果需要解释为最近的整数。Sep 12, 2016 - 林荟</code></pre>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://linhui.org/images/Jokes/jokeBayes.png&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;/p&gt;
&lt;h3 id=&quot;前提要求&quot;&gt;&lt;a href=&quot;#前提要求&quot; class=&quot;headerlink&quot; title=&quot;前提要求&quot;&gt;&lt;/a&gt;前提要求&lt;/h3&gt;&lt;p&gt;数据科学不是万能药，数据科学家也不是魔术师，有些问题我们无法用数据科学解决，最好在一开始就对问题做出判断，对于那些无法解决的问题，诚实的告诉对方并解释原因，那我们对问题有什么要求呢？&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="数据科学" scheme="https://zhenfenghan.github.io/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
  </entry>
  
  <entry>
    <title>为什么要用交叉验证（Cross-Validation）？</title>
    <link href="https://zhenfenghan.github.io/2018/07/15/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/"/>
    <id>https://zhenfenghan.github.io/2018/07/15/交叉验证/</id>
    <published>2018-07-15T02:01:11.000Z</published>
    <updated>2018-07-17T03:54:53.862Z</updated>
    
    <content type="html"><![CDATA[<h2 id="交叉验证：评估估算器的表现"><a href="#交叉验证：评估估算器的表现" class="headerlink" title="交叉验证：评估估算器的表现"></a>交叉验证：评估估算器的表现</h2><p><strong>交叉验证是一种模型校验方法，用来评价模型的泛化性。可以用来进行判断是否过拟合或者变量选择。</strong><br>学习预测函数的参数，并在相同数据集上进行测试是一种错误的做法: 一个仅给出测试用例标签的模型将会获得极高的分数，但对于尚未出现过的数据它则无法预测出任何有用的信息。 这种情况称为 <strong>overfitting（过拟合）</strong>. 为了避免这种情况，在进行（监督）机器学习实验时，通常取出部分可利用数据作为 <strong>test set（测试数据集）</strong> <code>X_test, y_test</code>。</p><p>需要强调的是这里说的 “experiment(实验)” 并不仅限于学术（academic），因为即使是在商业场景下机器学习也往往是从实验开始的。<br><a id="more"></a><br>在机器学习里，通常来说我们不能将全部用于数据训练模型，否则我们将没有数据集对该模型进行验证，从而评估我们的模型的预测效果。为了解决这一问题，有如下常用的方法：</p><h2 id="1-The-Validation-Set-Approach"><a href="#1-The-Validation-Set-Approach" class="headerlink" title="1.The Validation Set Approach"></a><em>1.The Validation Set Approach</em></h2><p>第一种是最简单的，也是很容易就想到的。我们可以把整个数据集分成两部分，一部分用于训练，一部分用于验证，这也就是我们经常提到的训练集（training set）和测试集（test set）。</p><p><img src="https://pic1.zhimg.com/80/v2-dc2ac40390791ca7f0ccf53cee0d4881_hd.jpg" alt=""></p><p>例如，如上图所示，我们可以将蓝色部分的数据作为训练集（包含7、22、13等数据），将右侧的数据作为测试集（包含91等），这样通过在蓝色的训练集上训练模型，在测试集上观察不同模型不同参数对应的MSE的大小，就可以合适选择模型和参数了。</p><p>不过，这个简单的方法存在两个弊端。</p><p>1.最终模型与参数的选取将极大程度依赖于你对训练集和测试集的划分方法。什么意思呢？我们再看一张图：</p><p><img src="https://pic1.zhimg.com/80/v2-577bb114a1073273452cc1c73045e274_hd.jpg" alt=""></p><p>右边是十种不同的训练集和测试集划分方法得到的test MSE，可以看到，在不同的划分方法下，test MSE的变动是很大的，而且对应的最优degree也不一样。所以如果我们的训练集和测试集的划分方法不够好，很有可能无法选择到最好的模型与参数。</p><p>2.该方法只用了部分数据进行模型的训练</p><p>我们都知道，当用于模型训练的数据量越大时，训练出来的模型通常效果会越好。所以训练集和测试集的划分意味着我们无法充分利用我们手头已有的数据，所以得到的模型效果也会受到一定的影响。</p><p>基于这样的背景，有人就提出了Cross-Validation方法，也就是交叉验证。</p><h2 id="2-Cross-Validation"><a href="#2-Cross-Validation" class="headerlink" title="2.Cross-Validation"></a><em>2.Cross-Validation</em></h2><p><em><strong>2.1 LOOCV</strong></em></p><p>首先，我们先介绍LOOCV方法，即（Leave-one-out cross-validation）。像Test set approach一样，LOOCV方法也包含将数据集分为训练集和测试集这一步骤。但是不同的是，我们现在只用一个数据作为测试集，其他的数据都作为训练集，并将此步骤重复N次（N为数据集的数据数量）。</p><p><img src="https://pic1.zhimg.com/80/v2-27f8c5989dd7790ccf6b626e6854e06c_hd.jpg" alt=""></p><p>如上图所示，假设我们现在有n个数据组成的数据集，那么LOOCV的方法就是每次取出一个数据作为测试集的唯一元素，而其他n-1个数据都作为训练集用于训练模型和调参。结果就是我们最终训练了n个模型，每次都能得到一个MSE。而计算最终test MSE则就是将这n个MSE取平均。</p><p><img src="https://pic1.zhimg.com/80/v2-c6a79e230f946da8aefd793ed57c0454_hd.jpg" alt=""></p><p><img src="https://www.zhihu.com/equation?tex=y_i" alt="">比起test set approach，LOOCV有很多优点。首先它不受测试集合训练集划分方法的影响，因为每一个数据都单独的做过测试集。同时，其用了n-1个数据训练模型，也几乎用到了所有的数据，保证了模型的bias更小。不过LOOCV的缺点也很明显，那就是计算量过于大，是test set approach耗时的n-1倍。</p><p>为了解决计算成本太大的弊端，又有人提供了下面的式子，使得LOOCV计算成本和只训练一个模型一样快。</p><p><img src="https://pic3.zhimg.com/80/v2-ec72b82d605902ddfa060c2fb5777a05_hd.jpg" alt=""></p><p>其中<img src="https://www.zhihu.com/equation?tex=%5Chat%7By_i%7D" alt="">表示第i个拟合值，而<img src="https://www.zhihu.com/equation?tex=h_i" alt="">则表示leverage。关于<img src="https://www.zhihu.com/equation?tex=h_i" alt="">的计算方法详见线性回归的部分（以后会涉及）。</p><p><em><strong>2.2 K-fold Cross Validation</strong></em></p><p>另外一种折中的办法叫做K折交叉验证，和LOOCV的不同在于，我们每次的测试集将不再只包含一个数据，而是多个，具体数目将根据K的选取决定。比如，如果K=5，那么我们利用五折交叉验证的步骤就是：</p><p>1.将所有数据集分成5份</p><p>2.不重复地每次取其中一份做测试集，用其他四份做训练集训练模型，之后计算该模型在测试集上的<img src="https://www.zhihu.com/equation?tex=MSE_i" alt=""></p><p>3.将5次的<img src="https://www.zhihu.com/equation?tex=MSE_i" alt="">取平均得到最后的MSE</p><p><img src="https://pic4.zhimg.com/80/v2-fcb843dd06c15a515d03a543864bbb77_hd.jpg" alt=""></p><p>不难理解，其实LOOCV是一种特殊的K-fold Cross Validation（K=N）。再来看一组图：</p><p><img src="https://pic1.zhimg.com/80/v2-daf077823e7faa57c6f4014389fe12b9_hd.jpg" alt=""></p><p>每一幅图种蓝色表示的真实的test MSE，而黑色虚线和橙线则分贝表示的是LOOCV方法和10-fold CV方法得到的test MSE。我们可以看到事实上LOOCV和10-fold CV对test MSE的估计是很相似的，但是相比LOOCV，10-fold CV的计算成本却小了很多，耗时更少。</p><p><strong><em>2.3 Bias-Variance Trade-Off for <strong>k</strong>-Fold Cross-Validation</em></strong></p><p>最后，我们要说说K的选取。事实上，和开头给出的文章里的部分内容一样，K的选取是一个Bias和Variance的trade-off。</p><p>K越大，每次投入的训练集的数据越多，模型的Bias越小。但是K越大，又意味着每一次选取的训练集之前的相关性越大（考虑最极端的例子，当k=N，也就是在LOOCV里，每次都训练数据几乎是一样的）。而这种大相关性会导致最终的test error具有更大的Variance。</p><p>一般来说，根据经验我们一般选择k=5或10。过小的k值（如k=2）将造成结果的波动性较大。</p><p>此外为使结果更加可靠，在k重交叉验证的基础上还可采用<strong>蒙特卡洛随机采样（Monte-Carlo random sampling）</strong>的方法，<strong>连续多次生成不同的随机子集</strong>划分方案并依次进行交叉验证，最终验证结果将<strong>根据随机次数取平均值</strong>。</p><pre><code>K-fold cross-validation (kFCV):</code></pre><p><a href="https://i.stack.imgur.com/fhMza.png" target="_blank" rel="noopener"><img src="https://i.stack.imgur.com/fhMza.png" alt=""></a></p><pre><code>Monte Carlo cross-validation (MCCV) = Repeated random sub-sampling validation (RRSSV):</code></pre><p><a href="https://i.stack.imgur.com/4Lrff.png" target="_blank" rel="noopener"><img src="https://i.stack.imgur.com/4Lrff.png" alt=""></a></p><hr><pre><code>References:</code></pre><blockquote><p>The pictures come from (1) (<a href="https://books.google.com/books?id=lessBQAAQBAJ&amp;pg=PA64&amp;lpg=PA64&amp;dq=Monte-Carlo+Cross+Validation+vs+Repeated+random+sub-sampling+validation&amp;source=bl&amp;ots=-psZ76bHJF&amp;sig=u45aULf3jGXlC17vpy93BNvNMPc&amp;hl=en&amp;sa=X&amp;ved=0ahUKEwiGrNqyxvfJAhUERyYKHTlFBQcQ6AEIPjAF#v=onepage&amp;q&amp;f=false" target="_blank" rel="noopener">pages 64 and 65</a>), and the synonym is mentioned in (1) and (2).</p></blockquote><ul><li><p>(1) Remesan, Renji, and Jimson Mathew. <a href="https://scholar.google.com/scholar?cluster=3631137316277879397&amp;hl=en&amp;as_sdt=0,22" target="_blank" rel="noopener">Hydrological Data Driven Modelling: A Case Study Approach</a>. Vol. 1. Springer, 2014.</p></li><li><p>(2) Dubitzky, Werner, Martin Granzow, and Daniel P. Berrar, eds. <a href="https://scholar.google.com/scholar?cluster=16367872026873385572&amp;hl=en&amp;as_sdt=0,22" target="_blank" rel="noopener">Fundamentals of data mining in genomics and proteomics</a>. Springer Science &amp; Business Media, 2007.  </p></li></ul><p><em><strong>2.4 Cross-Validation on Classification Problems</strong></em></p><p>上面我们讲的都是回归问题，所以用MSE来衡量test error。如果是分类问题，那么我们可以用以下式子来衡量Cross-Validation的test error：</p><p><img src="https://pic4.zhimg.com/80/v2-7302b5c15dcfc6746b51830b65debf62_hd.jpg" alt=""></p><p>其中Erri表示的是第i个模型在第i组测试集上的分类错误的个数。</p><p>图片来源：《An Introduction to Statistical Learning with Applications in R》</p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;交叉验证：评估估算器的表现&quot;&gt;&lt;a href=&quot;#交叉验证：评估估算器的表现&quot; class=&quot;headerlink&quot; title=&quot;交叉验证：评估估算器的表现&quot;&gt;&lt;/a&gt;交叉验证：评估估算器的表现&lt;/h2&gt;&lt;p&gt;&lt;strong&gt;交叉验证是一种模型校验方法，用来评价模型的泛化性。可以用来进行判断是否过拟合或者变量选择。&lt;/strong&gt;&lt;br&gt;学习预测函数的参数，并在相同数据集上进行测试是一种错误的做法: 一个仅给出测试用例标签的模型将会获得极高的分数，但对于尚未出现过的数据它则无法预测出任何有用的信息。 这种情况称为 &lt;strong&gt;overfitting（过拟合）&lt;/strong&gt;. 为了避免这种情况，在进行（监督）机器学习实验时，通常取出部分可利用数据作为 &lt;strong&gt;test set（测试数据集）&lt;/strong&gt; &lt;code&gt;X_test, y_test&lt;/code&gt;。&lt;/p&gt;
&lt;p&gt;需要强调的是这里说的 “experiment(实验)” 并不仅限于学术（academic），因为即使是在商业场景下机器学习也往往是从实验开始的。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="交叉验证" scheme="https://zhenfenghan.github.io/tags/%E4%BA%A4%E5%8F%89%E9%AA%8C%E8%AF%81/"/>
    
  </entry>
  
  <entry>
    <title>回归分析--预测神器</title>
    <link href="https://zhenfenghan.github.io/2018/07/13/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90/"/>
    <id>https://zhenfenghan.github.io/2018/07/13/回归分析/</id>
    <published>2018-07-13T02:01:11.000Z</published>
    <updated>2018-07-18T02:51:15.241Z</updated>
    
    <content type="html"><![CDATA[<blockquote><p>回归分析 : 是一种预测性的建模技术,使用曲线拟合数据点，最终获取到数据点的距离差异最小的曲线</p></blockquote><figure class="highlight plain"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">回归主要三个度量：自变量的个数，因变量的类型以及回归线的形状</span><br></pre></td></tr></table></figure><h2 id="什么是回归分析？"><a href="#什么是回归分析？" class="headerlink" title="什么是回归分析？"></a><strong>什么是回归分析？</strong></h2><p>回归分析是一种预测性的建模技术，它研究的是因变量（目标）和自变量（预测器）之间的关系。这种技术通常用于预测分析，时间序列模型以及发现变量之间的<a href="http://www.analyticsvidhya.com/blog/2015/06/establish-causality-events/" target="_blank" rel="noopener">因果关系</a>。例如，司机的鲁莽驾驶与道路交通事故数量之间的关系，最好的研究方法就是回归。</p><p>回归分析是建模和分析数据的重要工具。在这里，我们使用曲线/线来拟合这些数据点，在这种方式下，从曲线或线到数据点的距离差异最小。我会在接下来的部分详细解释这一点。</p><p><img src="http://img.ptcms.csdn.net/article/201508/19/55d3f54edbb07_middle.jpg?_=34626" alt=""><br><a id="more"></a></p><h2 id="我们为什么使用回归分析？"><a href="#我们为什么使用回归分析？" class="headerlink" title="我们为什么使用回归分析？"></a><strong>我们为什么使用回归分析？</strong></h2><p>如上所述，回归分析估计了两个或多个变量之间的关系。下面，让我们举一个简单的例子来理解它：</p><p>比如说，在当前的经济条件下，你要估计一家公司的销售额增长情况。现在，你有公司最新的数据，这些数据显示出销售额增长大约是经济增长的2.5倍。那么使用回归分析，我们就可以根据当前和过去的信息来预测未来公司的销售情况。</p><p>使用回归分析的好处良多。具体如下：</p><ol><li>它表明自变量和因变量之间的<strong>显著关系</strong>；</li><li>它表明多个自变量对一个因变量的<strong>影响强度</strong>。</li></ol><p>回归分析也允许我们去比较那些衡量不同尺度的变量之间的相互影响，如价格变动与促销活动数量之间联系。这些有利于帮助市场研究人员，数据分析人员以及数据科学家排除并估计出一组最佳的变量，用来构建预测模型。</p><h2 id="我们有多少种回归技术？"><a href="#我们有多少种回归技术？" class="headerlink" title="我们有多少种回归技术？"></a><strong>我们有多少种回归技术？</strong></h2><p>有各种各样的回归技术用于预测。这些技术主要有三个度量（自变量的个数，因变量的类型以及回归线的形状）。我们将在下面的部分详细讨论它们。</p><p><img src="http://img.ptcms.csdn.net/article/201508/19/55d3f5b3903b4_middle.jpg?_=19921" alt=""></p><p>对于那些有创意的人，如果你觉得有必要使用上面这些参数的一个组合，你甚至可以创造出一个没有被使用过的回归模型。但在你开始之前，先了解如下最常用的回归方法：</p><h3 id="线性回归-（Linear-Regression）"><a href="#线性回归-（Linear-Regression）" class="headerlink" title="线性回归 （Linear Regression）"></a>线性回归 （Linear Regression）</h3><blockquote><p>因变量是连续的，自变量可以是连续的也可以是离散的，回归线的性质是线性的。</p></blockquote><p>线性回归使用最佳的拟合直线（也就是回归线）在因变量（Y）和一个或多个自变量（X）之间建立一种关系。</p><p>用一个方程式来表示它，即Y=a+b*X + e，其中a表示截距，b表示直线的斜率，e是误差项。这个方程可以根据给定的预测变量（s）来预测目标变量的值。</p><p>一元线性回归和多元线性回归的区别在于，多元线性回归有（&gt;1）个自变量，而一元线性回归通常只有1个自变量。<br>我们可以对多变量线性回归建模如下：</p><p><img src="http://imgtec.eetrend.com/sites/imgtec.eetrend.com/files/201804/blog/11428-33366-1.jpg" alt=""></p><p>其中是系数，是变量，是偏置。正如我们所看到的，这个函数只有线性关系，所以它只适用于建模线性可分数据。这很容易理解，因为我们只是使用系数权重来加权每个特征变量的重要性。我们使用随机梯度下降（SGD）来确定这些权重和偏置b。具体过程如下图所示：</p><p><img src="http://imgtec.eetrend.com/sites/imgtec.eetrend.com/files/201804/blog/11428-33358-2.gif" alt=""></p><ul><li>自变量与因变量之间必须有线性关系</li><li>多元回归存在多重共线性，自相关性和异方差性。</li><li>线性回归对异常值非常敏感。它会严重影响回归线，最终影响预测值。</li><li>多重共线性会增加系数估计值的方差，使得在模型轻微变化下，估计非常敏感。结果就是系数估计值不稳定</li><li>在多个自变量的情况下，我们可以使用向前选择法，向后剔除法和逐步筛选法来选择最重要的自变量。</li></ul><h3 id="逻辑回归-（Logistic-Regression）"><a href="#逻辑回归-（Logistic-Regression）" class="headerlink" title="逻辑回归 （Logistic Regression）"></a>逻辑回归 （Logistic Regression）</h3><blockquote><p>逻辑回归是用来计算“事件=Success”和“事件=Failure”的概率。当因变量的类型属于二元（1 / 0，真/假，是/否）变量时，我们就应该使用逻辑回归。</p></blockquote><p>因为在这里我们使用的是的二项分布（因变量），我们需要选择一个对于这个分布最佳的连结函数。它就是Logit函数。在上述方程中，通过观测样本的极大似然估计值来选择参数，而不是最小化平方和误差（如在普通回归使用的）。</p><ul><li>它广泛的用于分类问题。</li><li>逻辑回归不要求自变量和因变量是线性关系。它可以处理各种类型的关系，因为它对预测的相对风险指数OR使用了一个非线性的log转换。</li><li>为了避免过拟合和欠拟合，我们应该包括所有重要的变量。有一个很好的方法来确保这种情况，就是使用逐步筛选方法来估计逻辑回归。</li><li>它需要大的样本量，因为在样本数量较少的情况下，极大似然估计的效果比普通的最小二乘法差。</li><li>自变量不应该相互关联的，即不具有多重共线性。然而，在分析和建模中，我们可以选择包含分类变量相互作用的影响。</li><li>如果因变量的值是定序变量，则称它为序逻辑回归。</li><li>如果因变量是多类的话，则称它为多元逻辑回归。</li></ul><h3 id="多项式回归-（Polynomial-Regression）"><a href="#多项式回归-（Polynomial-Regression）" class="headerlink" title="多项式回归 （Polynomial Regression）"></a>多项式回归 （Polynomial Regression）</h3><blockquote><p>对于一个回归方程，如果自变量的指数大于1，那么它就是多项式回归方程。</p></blockquote><p>在这种回归模型中，最佳拟合线不是直线。而是一个用于拟合数据点的曲线。<br>当我们要创建适合处理非线性可分数据的模型时，我们需要使用多项式回归。在这种回归技术中，最佳拟合线不是一条直线，而是一条符合数据点的曲线。对于一个多项式回归，一些自变量的指数是大于1的。例如，我们可以有这下式：</p><p><img src="http://imgtec.eetrend.com/sites/imgtec.eetrend.com/files/201804/blog/11428-33367-3.jpg" alt=""></p><p>一些变量有指数，其他变量没有。然而，选择每个变量的确切指数自然需要当前数据集合与最终输出的一些先验知识。请参阅下面的图，了解线性与多项式回归的比较。</p><p><img src="http://imgtec.eetrend.com/sites/imgtec.eetrend.com/files/201804/blog/11428-33360-4.gif" alt=""></p><p><img src="http://imgtec.eetrend.com/sites/imgtec.eetrend.com/files/201804/blog/11428-33361-5.gif" alt=""></p><ul><li>虽然会有一个诱导可以拟合一个高次多项式并得到较低的错误，但这可能会导致过拟合。你需要经常画出关系图来查看拟合情况，并且专注于保证拟合合理，既没有过拟合又没有欠拟合。</li><li>明显地向两端寻找曲线点，看看这些形状和趋势是否有意义。更高次的多项式最后可能产生怪异的推断结果。</li><li>能够模拟非线性可分的数据;线性回归不能做到这一点。它总体上更灵活，可以模拟一些相当复杂的关系。</li><li>完全控制要素变量的建模（要设置变量的指数）。</li><li>需要仔细的设计。需要一些数据的先验知识才能选择最佳指数。</li></ul><h3 id="逐步回归-（Stepwise-Regression）"><a href="#逐步回归-（Stepwise-Regression）" class="headerlink" title="逐步回归 （Stepwise Regression）"></a>逐步回归 （Stepwise Regression）</h3><blockquote><p>在处理多个自变量时，我们可以使用这种形式的回归。</p></blockquote><p>这一壮举是通过观察统计的值，如R-square，t-stats和AIC指标，来识别重要的变量。逐步回归通过同时添加/删除基于指定标准的协变量来拟合模型。下面列出了一些最常用的逐步回归方法：</p><ul><li>标准逐步回归法做两件事情。即增加和删除每个步骤所需的预测。</li><li>向前选择法从模型中最显著的预测开始，然后为每一步添加变量。</li><li>向后剔除法与模型的所有预测同时开始，然后在每一步消除最小显着性的变量。</li></ul><p>这种建模技术的目的是使用最少的预测变量数来最大化预测能力。这也是处理高维数据集的方法之一。</p><h3 id="岭回归-（Ridge-Regression）"><a href="#岭回归-（Ridge-Regression）" class="headerlink" title="岭回归 （Ridge Regression）"></a>岭回归 （Ridge Regression）</h3><blockquote><p>岭回归分析是一种用于存在多重共线性（自变量高度相关）数据的技术。</p></blockquote><p>在多重共线性情况下，尽管最小二乘法（OLS）对每个变量很公平，但它们的差异很大，使得观测值偏移并远离真实值。岭回归通过给回归估计上增加一个偏差度，来降低标准误差。</p><p>在一个线性方程中，预测误差可以分解为2个子分量。一个是偏差，一个是方差。预测错误可能会由这两个分量或者这两个中的任何一个造成。    </p><p>我们进行回归分析需要了解每个自变量对因变量的单纯效应，高共线性就是说自变量间存在某种函数关系，如果你的两个自变量间（X1和X2）存在函数关系，那么X1改变一个单位时，X2也会相应地改变，此时你无法做到固定其他条件，单独考查X1对因变量Y的作用，你所观察到的X1的效应总是混杂了X2的作用，这就造成了分析误差，使得对自变量效应的分析不准确，所以做回归分析时需要排除高共线性的影响。<br>我们可以首先看一下标准线性回归的优化函数，然后看看岭回归如何解决上述问题的思路：</p><p><img src="http://imgtec.eetrend.com/sites/imgtec.eetrend.com/files/201804/blog/11428-33368-6.jpg" alt=""></p><pre><code>其中X表示特征变量，w表示权重，y表示真实情况。岭回归是缓解模型中回归预测变量之间共线性的一种补救措施。由于共线性，多元回归模型中的一个特征变量可以由其他变量进行线性预测。  </code></pre><p>岭回归通过<a href="https://en.wikipedia.org/wiki/Shrinkage_estimator" target="_blank" rel="noopener">收缩参数</a>λ（lambda）解决多重共线性问题。看下面的公式</p><p><img src="http://img.ptcms.csdn.net/article/201508/19/55d3f6f3add20.jpg" alt=""></p><pre><code>在这个公式中，有两个组成部分。第一个是最小二乘项，另一个是β2（β-平方）的λ倍，其中β是相关系数。为了收缩参数把它添加到最小二乘项中以得到一个非常低的方差。</code></pre><ul><li>除常数项以外，这种回归的假设与最小二乘回归类似；</li><li>它收缩了相关系数的值，但没有达到零，这表明它没有特征选择功能</li><li>这是一个正则化方法，并且使用的是L2正则化。</li><li>这种回归的假设与最小平方回归相同，不同点在于最小平方回归的时候，我们假设数据的误差服从高斯分布使用的是极大似然估计（MLE），在岭回归的时候，由于添加了偏差因子，即w的先验信息，使用的是极大后验估计（MAP）来得到最终参数的。</li></ul><h3 id="套索回归-（Lasso-Regression）"><a href="#套索回归-（Lasso-Regression）" class="headerlink" title="套索回归 （Lasso Regression）"></a>套索回归 （Lasso Regression）</h3><blockquote><p>它类似于岭回归，Lasso （Least Absolute Shrinkage and Selection Operator）也会惩罚回归系数的绝对值大小。</p></blockquote><p>此外，它能够减少变化程度并提高线性回归模型的精度。<br><img src="http://img.ptcms.csdn.net/article/201508/19/55d3f7141b25b.jpg" alt=""><br>Lasso 回归与Ridge回归有一点不同，它使用的惩罚函数是绝对值，而不是平方。这导致惩罚（或等于约束估计的绝对值之和）值使一些参数估计结果等于零。使用惩罚值越大，进一步估计会使得缩小值趋近于零。这将导致我们要从给定的n个变量中选择变量。<br>岭回归和Lasso回归之间存在一些差异，基本上可以归结为L2和L1正则化的性质差异：</p><p><strong>• 内置的特征选择（Built-in feature selection）：</strong>这是L1范数的一个非常有用的属性，而L2范数不具有这种特性。这实际上因为是L1范数倾向于产生稀疏系数。例如，假设模型有100个系数，但其中只有10个系数是非零系数，这实际上是说“其他90个变量对预测目标值没有用处”。 而L2范数产生非稀疏系数，所以没有这个属性。因此，可以说Lasso回归做了一种“参数选择”形式，未被选中的特征变量对整体的权重为0。</p><p><strong>• 稀疏性：</strong>指矩阵（或向量）中只有极少数条目非零。 L1范数具有产生具有零值或具有很少大系数的非常小值的许多系数的属性。</p><p><strong>• 计算效率：</strong>L1范数没有解析解，但L2范数有。这使得L2范数的解可以通过计算得到。然而，L1范数的解具有稀疏性，这使得它可以与稀疏算法一起使用，这使得在计算上更有效率。</p><ul><li>除常数项以外，这种回归的假设与最小二乘回归类似；</li><li>它收缩系数接近零（等于零），这确实有助于特征选择；</li><li>这是一个正则化方法，使用的是L1正则化；</li></ul><p>如果预测的一组变量是高度相关的，Lasso 会选出其中一个变量并且将其它的收缩为零。</p><h3 id="弹性网络回归（ElasticNet-Regression）"><a href="#弹性网络回归（ElasticNet-Regression）" class="headerlink" title="弹性网络回归（ElasticNet Regression）"></a>弹性网络回归（ElasticNet Regression）</h3><blockquote><p>ElasticNet是Lasso和Ridge回归技术的混合体。</p></blockquote><p>它使用L1来训练并且L2优先作为正则化矩阵。当有多个相关的特征时，ElasticNet是很有用的。Lasso 会随机挑选他们其中的一个，而ElasticNet则会选择两个。  </p><p><img src="http://img.ptcms.csdn.net/article/201508/19/55d3f736bb158.jpg" alt=""><br>Lasso和Ridge之间的实际的优点是，它允许ElasticNet继承循环状态下Ridge的一些稳定性。</p><ul><li>它鼓励在高度相关变量的情况下的群体效应，而不是像Lasso那样将其中一些置零。当多个特征和另一个特征相关的时候弹性网络非常有用。Lasso 倾向于随机选择其中一个，而弹性网络更倾向于选择两个。（<strong>在高度相关变量的情况下，它会产生群体效应</strong>）；</li><li>选择变量的数目没有限制；</li><li>它可以承受双重收缩。   </li></ul><h3 id="拓展：损失函数和正则化"><a href="#拓展：损失函数和正则化" class="headerlink" title="拓展：损失函数和正则化"></a>拓展：损失函数和正则化</h3><p><strong>损失函数（loss function）</strong>是用来估量你模型的预测值f(x)与真实值Y的不一致程度，它是一个非负实值函数,通常使用L(Y, f(x))来表示，损失函数越小，模型的鲁棒性就越好。损失函数是<strong>经验风险函数</strong>的核心部分，也是<strong>结构风险函数</strong>重要组成部分。模型的结构风险函数包括了经验风险项和正则项，通常可以表示成如下式子：</p><p>\theta^* = \arg \min_\theta \frac{1}{N}{}\sum_{i=1}^{N} L(y_i, f(x_i; \theta)) + \lambda\ \Phi(\theta)</p><p>其中，前面的均值函数表示的是经验风险函数，L代表的是损失函数，后面的Φ是正则化项（regularizer）或者叫惩罚项（penalty term），它可以是L1，也可以是L2，或者其他的正则函数。整个式子表示的意思是<strong>找到使目标函数最小时的θ值</strong>。</p><p><strong>L1正则化和L2正则化的说明如下：</strong></p><ul><li><p>L1正则化是指权值向量ww中各个元素的<strong><em>绝对值之和</em></strong>，通常表示为||w||1</p></li><li><p>L2正则化是指权值向量ww中各个元素的<strong><em>平方和然后再求平方根</em></strong>（可以看到Ridge回归的L2正则化项有平方符号），通常表示为||w||2</p></li></ul><p>一般都会在正则化项之前添加一个系数，Python中用αα表示，一些文章也用λλ表示。<strong>这个系数需要用户指定。</strong></p><p>那添加L1和L2正则化有什么用？<strong>下面是L1正则化和L2正则化的作用</strong>，这些表述可以在很多文章中找到。</p><ul><li>L1正则化可以产生稀疏权值矩阵，即产生一个稀疏模型，可以用于特征选择</li><li>L2正则化可以防止模型过拟合（overfitting）；一定程度上，L1也可以防止过拟合</li></ul><h4 id="稀疏模型与特征选择"><a href="#稀疏模型与特征选择" class="headerlink" title="稀疏模型与特征选择"></a>稀疏模型与特征选择</h4><p>上面提到L1正则化有助于生成一个稀疏权值矩阵，进而可以用于特征选择。<strong>为什么要生成一个稀疏矩阵？</strong></p><p>稀疏矩阵指的是很多元素为0，只有少数元素是非零值的矩阵，即得到的线性回归模型的大部分系数都是0. 通常机器学习中特征数量很多，例如文本处理时，如果将一个词组（term）作为一个特征，那么特征数量会达到上万个（bigram）。在预测或分类时，那么多特征显然难以选择，但是如果代入这些特征得到的模型是一个稀疏模型，表示只有少数特征对这个模型有贡献，绝大部分特征是没有贡献的，或者贡献微小（因为它们前面的系数是0或者是很小的值，即使去掉对模型也没有什么影响），此时我们就可以<strong>只关注系数是非零值的特征</strong>。这就是稀疏模型与特征选择的关系。</p><p><strong>Reference</strong></p><p>过拟合的解释：<br><a href="https://hit-scir.gitbooks.io/neural-networks-and-deep-learning-zh_cn/content/chap3/c3s5ss2.html" target="_blank" rel="noopener">https://hit-scir.gitbooks.io/neural-networks-and-deep-learning-zh_cn/content/chap3/c3s5ss2.html</a></p><p>正则化的解释：<br><a href="https://hit-scir.gitbooks.io/neural-networks-and-deep-learning-zh_cn/content/chap3/c3s5ss1.html" target="_blank" rel="noopener">https://hit-scir.gitbooks.io/neural-networks-and-deep-learning-zh_cn/content/chap3/c3s5ss1.html</a></p><p>正则化的解释：<br><a href="http://blog.csdn.net/u012162613/article/details/44261657" target="_blank" rel="noopener">http://blog.csdn.net/u012162613/article/details/44261657</a></p><p>正则化的数学解释：<br><a href="http://blog.csdn.net/zouxy09/article/details/24971995" target="_blank" rel="noopener">http://blog.csdn.net/zouxy09/article/details/24971995</a></p><h2 id="如何正确选择回归模型？"><a href="#如何正确选择回归模型？" class="headerlink" title="如何正确选择回归模型？"></a><strong>如何正确选择回归模型？</strong></h2><p><strong>当你只知道一个或两个技术时，生活往往很简单。</strong>我知道的一个培训机构告诉他们的学生，如果结果是连续的，就使用线性回归。如果是二元的，就使用逻辑回归！然而，在我们的处理中，可选择的越多，选择正确的一个就越难。类似的情况下也发生在回归模型中。</p><p>在多类回归模型中，基于自变量和因变量的类型，数据的维数以及数据的其它基本特征的情况下，选择最合适的技术非常重要。以下是你要选择正确的回归模型的关键因素：</p><blockquote><ol><li>数据探索是构建预测模型的必然组成部分。在选择合适的模型时，比如识别变量的关系和影响时，它应该首选的一步。</li><li>比较适合于不同模型的优点，我们可以分析不同的指标参数，如统计意义的参数，R-square，Adjusted R-square，AIC，BIC以及误差项，另一个是<a href="http://support.minitab.com/en-us/minitab/17/topic-library/modeling-statistics/regression-and-correlation/goodness-of-fit-statistics/what-is-mallows-cp/" target="_blank" rel="noopener">Mallows’ Cp</a>准则。这个主要是通过将模型与所有可能的子模型进行对比（或谨慎选择他们），检查在你的模型中可能出现的偏差。</li><li><strong>交叉验证是评估预测模型最好的方法</strong>。在这里，将你的数据集分成两份（一份做训练和一份做验证）。<strong>使用观测值和预测值之间的一个简单均方差来衡量你的预测精度。</strong></li><li>如果你的数据集是多个混合变量，那么你就不应该选择自动模型选择方法，因为你应该不想在同一时间把所有变量放在同一个模型中。</li><li>它也将<strong>取决于你的目的</strong>。可能会出现这样的情况，一个不太强大的模型与具有高度统计学意义的模型相比，更易于实现。</li><li><strong>回归正则化方法（Lasso，Ridge和ElasticNet）在高维和数据集变量之间多重共线性情况下运行良好。</strong></li></ol></blockquote><blockquote><p>原文<br><a href="https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/" target="_blank" rel="noopener">https://www.analyticsvidhya.com/blog/2015/08/comprehensive-guide-regression/</a><br><a href="https://towardsdatascience.com/5-types-of-regression-and-their-properties-c5e1fa12d55e" target="_blank" rel="noopener">https://towardsdatascience.com/5-types-of-regression-and-their-propertie…</a><br>译文<br><a href="http://blog.csdn.net/lynnucas/article/details/47948639" target="_blank" rel="noopener">http://blog.csdn.net/lynnucas/article/details/47948639</a></p></blockquote><hr>]]></content>
    
    <summary type="html">
    
      &lt;blockquote&gt;
&lt;p&gt;回归分析 : 是一种预测性的建模技术,使用曲线拟合数据点，最终获取到数据点的距离差异最小的曲线&lt;/p&gt;
&lt;/blockquote&gt;
&lt;figure class=&quot;highlight plain&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;回归主要三个度量：自变量的个数，因变量的类型以及回归线的形状&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;h2 id=&quot;什么是回归分析？&quot;&gt;&lt;a href=&quot;#什么是回归分析？&quot; class=&quot;headerlink&quot; title=&quot;什么是回归分析？&quot;&gt;&lt;/a&gt;&lt;strong&gt;什么是回归分析？&lt;/strong&gt;&lt;/h2&gt;&lt;p&gt;回归分析是一种预测性的建模技术，它研究的是因变量（目标）和自变量（预测器）之间的关系。这种技术通常用于预测分析，时间序列模型以及发现变量之间的&lt;a href=&quot;http://www.analyticsvidhya.com/blog/2015/06/establish-causality-events/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;因果关系&lt;/a&gt;。例如，司机的鲁莽驾驶与道路交通事故数量之间的关系，最好的研究方法就是回归。&lt;/p&gt;
&lt;p&gt;回归分析是建模和分析数据的重要工具。在这里，我们使用曲线/线来拟合这些数据点，在这种方式下，从曲线或线到数据点的距离差异最小。我会在接下来的部分详细解释这一点。&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;http://img.ptcms.csdn.net/article/201508/19/55d3f54edbb07_middle.jpg?_=34626&quot; alt=&quot;&quot;&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="数据科学" scheme="https://zhenfenghan.github.io/tags/%E6%95%B0%E6%8D%AE%E7%A7%91%E5%AD%A6/"/>
    
      <category term="回归分析 - 预测" scheme="https://zhenfenghan.github.io/tags/%E5%9B%9E%E5%BD%92%E5%88%86%E6%9E%90-%E9%A2%84%E6%B5%8B/"/>
    
  </entry>
  
  <entry>
    <title>医疗健康行业之管窥一斑</title>
    <link href="https://zhenfenghan.github.io/2018/07/08/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B7/"/>
    <id>https://zhenfenghan.github.io/2018/07/08/医疗健康/</id>
    <published>2018-07-08T02:01:11.000Z</published>
    <updated>2018-07-18T13:42:01.963Z</updated>
    
    <content type="html"><![CDATA[<h3 id="探索生命的更多可能性"><a href="#探索生命的更多可能性" class="headerlink" title="探索生命的更多可能性"></a>探索生命的更多可能性</h3><p><div align="center"><br><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B7.jpg" alt="yiliaojiankang.jpg"><br></div></p><h4 id="一、市场容量及趋势"><a href="#一、市场容量及趋势" class="headerlink" title="一、市场容量及趋势"></a>一、市场容量及趋势</h4><p>前瞻产业研究院数据显示，2016年，中国的医疗健康产业市场规模接近3万亿元;据《“健康中国2020”战略规划》、《“健康中国2030”战略规划》，健康服务业的总规模到2020年要做到八万亿，2030年要达到<strong>十六万亿</strong>。医疗健康目前是美国最赚钱的行业，在投资回报率、收益率等方面也都排在第一。<br><a id="more"></a><br><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B71.png" alt=""></p><p>作为国计民生的重要行业医疗健康行业仍在稳步成长中，中国已成为仅次于美国的全球第二大医药市场，且仍保持每年<strong>10%</strong> 以上的增速。<strong>创新跨界将会是2018年的主题</strong>。</p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B72.png" alt=""></p><h4 id="二、行业细分板块"><a href="#二、行业细分板块" class="headerlink" title="二、行业细分板块"></a>二、行业细分板块</h4><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B73.png" alt=""><br><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B74.png" alt=""></p><p>其中医疗器械重点关注领域为：<br><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B75.png" alt=""></p><p>同时<strong>不同医疗健康领域的价值创造来源存在差异。</strong>  </p><p>对于制药和生物科技领域而言，科学和技术创新以及在本土开展相关创新的快速跟随者，贡献了 90% 的价值创造。但在医疗技术领域，在本土开展相关创新的快速跟随者和成本的竞争优势贡献了 80% 的价值创造。与之形成鲜明对比的是，医疗健康科技（例如大数据、分析、人工智能）有 60% 的价值创造来自对医疗健康价值链的颠覆。</p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B76.png" alt="价值创造差异.jpg"></p><h4 id="三、医疗健康行业职能细分"><a href="#三、医疗健康行业职能细分" class="headerlink" title="三、医疗健康行业职能细分"></a>三、医疗健康行业职能细分</h4><p><strong>制药业</strong>保持稳定增长，尤其是创新药物和高质量药物，中国新药研发正在迎来黄金时代；<strong>医疗器械</strong>的创新能力不断增强，关键技术不断取得突破，特别是高端医疗器械的创新研发进程将进一步加快；<strong>医疗服务</strong>需求旺盛，与医疗行业相配套的医疗信息化等产业相应增长。</p><p>跨行业进入者众多，医药行业的人才需求从数量上到质量上都到达了一个前所未有的高度。<br><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B77.png" alt=""></p><h5 id="制药和医疗器械"><a href="#制药和医疗器械" class="headerlink" title="制药和医疗器械"></a><strong><em>制药和医疗器械</em></strong></h5><p>市场保持健康增长。新药研发投入加大、仿制药一致性评价、新药审评提速、药品招标和两票制的实施，导致以下人才缺口的扩大。</p><p><strong>人才缺口：</strong>研发总监、注册总监、投资并购总监、营销副总裁、准入策略总监、国际营销和合作总监、非医药行业公司的医疗健康事业部负责人<br><strong>人才来源：</strong>同类公司、基金、海外医药公司、医药咨询公司</p><h5 id="医疗服务人才"><a href="#医疗服务人才" class="headerlink" title="医疗服务人才"></a><strong><em>医疗服务人才</em></strong></h5><p>目前的医疗服务能力明显不能满足不同层次的人群的多样化需求。人们健康意识提高、人口老龄化、国家鼓励非公立医疗机构、以及金融、地产行业进入医疗服务，导致医疗服务相关人才需求激增。</p><p><strong>人才缺口：</strong>医疗事业部负责人、运营副总、医务总监、护理总监、高级医生</p><p><strong>人才来源：</strong>非公立和公立医疗机构、海外医疗服务机构、酒店等高端服务性行业</p><h5 id="医疗信息化和互联网医疗"><a href="#医疗信息化和互联网医疗" class="headerlink" title="医疗信息化和互联网医疗"></a><em>医疗信息化和互联网医疗</em></h5><p>随着“互联网+”和物联网的快速发展，医疗健康行业为了提高服务能力和管理效率纷纷拥抱IT技术和互联网。互联网行业也盯上了医疗健康这块数万亿的蛋糕。 </p><p><strong>人才缺口：</strong>营销副总、研发总监、大数据人才</p><p><strong>人才来源：</strong>医药公司、医疗信息化公司、移动医疗和互联网医疗公司、互联网公司</p><h5 id="个体化医疗相关公司"><a href="#个体化医疗相关公司" class="headerlink" title="个体化医疗相关公司"></a><em>个体化医疗相关公司</em></h5><p>基因测序效率提高，成本降低，对于药物研发、疾病治疗和预防起到了越来越重要的作用。靶向药物的研发在国内外均取得明显进展。华大基因和贝瑞基因在2017年的上市更加鼓励了资本在个体化医疗的投入。行业急缺在基因诊断、精准医疗、通过大数据进行诊疗方法开发的专业人士和市场推广人士。 </p><p><strong>人才缺口：</strong>医学总监、营销总监、数据分析</p><p><strong>人才来源：</strong>医药和医疗器械公司、医院、互联网公司</p><h4 id="职位薪酬信息"><a href="#职位薪酬信息" class="headerlink" title="职位薪酬信息"></a><strong><em>职位薪酬信息</em></strong></h4><h4 id="医药"><a href="#医药" class="headerlink" title="医药"></a>医药</h4><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B78.png" alt=""></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B79.png" alt=""></p><h4 id="器械设备"><a href="#器械设备" class="headerlink" title="器械设备"></a>器械设备</h4><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B710.png" alt=""></p><h4 id="医疗服务"><a href="#医疗服务" class="headerlink" title="医疗服务"></a>医疗服务</h4><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B711.png" alt=""></p><h4 id="个体化医疗"><a href="#个体化医疗" class="headerlink" title="个体化医疗"></a>个体化医疗</h4><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B712.png" alt=""></p><p>备注：<br>基本年薪<em>：以人民币 1000元为单位，指年度整体的现金收入=年度底薪+年度固定部分奖金<br>25 分位值：表示有 25%的数据小于此数值，反映科锐国际信息库的较低端水平<br>50 分位值（中位值）：表示有 50%的数据小于此数值，反映科锐国际信息库的中等水平<br>75 分位值：表示有 75%的数据小于此数值，反映科锐国际信息库的较高端水平<br>一线城市</em>：北京、上海、广州、深圳<br>二线城市*：省会及热点城市，例如天津、苏州、杭州、重庆、成都</p><h4 id="四、相关拓展"><a href="#四、相关拓展" class="headerlink" title="四、相关拓展"></a>四、相关拓展</h4><h5 id="（1）AI-医疗"><a href="#（1）AI-医疗" class="headerlink" title="（1）AI 医疗"></a>（1）AI 医疗</h5><p>AI医疗是以互联网为依托，通过基础设施的搭建及数据的收集，将人工智能技术及大数据服务应用于医疗行业中，提升医疗行业的诊断效率及服务质量，更好的解决医疗资源短缺、人口老龄化的问题。</p><p><strong> AI医疗定义金字塔</strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B713.png" alt=""></p><ul><li>基础层：通过软硬件的基础设施，收集用户、药物及病理数据，并使数据互通互联，为人工智能的应用提供支持与可能。</li><li>技术层：通过语音/语义识别、计算机视觉技术，对非结构化数据进行分析提炼。“学习”大量病理学数据文本，使其掌握问答、判断、预警、实施的能力。</li><li>应用层：是指人工智能与不同细分领域的结合，以解决医疗行业中的某种业务需求，如智能诊断、药物研发、智能健康管理、智能语音等医疗场景。</li></ul><p><strong>国内资本多布局虚拟助手、医疗影像、医用机器人、智能健康管理这四个领域</strong></p><p>经统计，从13年到17年上半年，应用层8个细分领域共发生融资事件86起。国内资本多布局虚拟助手、医疗影像、医用机器人、智能健康管理四个领域，其中<strong>医疗影像</strong>成为资本密集的阵地，占比最高达到31%，位居第一。</p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B714.png" alt=""></p><p>因为影像具有4V性（<strong>volume数量、variety多样性、velocity速度、veracity真实性</strong>），4V的属性更适合其AI的发展。</p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B715.png" alt="">  </p><h5 id="（2）移动健康"><a href="#（2）移动健康" class="headerlink" title="（2）移动健康"></a>（2）移动健康</h5><p>涵盖12个医疗细分领域，美国现有最全的主流医疗健康领域移动App的应用场景和功能基本上涵盖于此，以下是简要介绍。</p><pre><code>1、远程医疗服务</code></pre><p><strong><em>Doctor on Demand</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B716.png" alt=""></p><p>由美国电视达人Dr. Phil和他儿子创办的公司。利用智能手机App链接患者和他们咨询的医生，以每次40美元的收费，为病人提供电脑或手机的远程医学访问。除内科和儿科治疗，该App还会提供一个25-50分钟的心理学研讨会和哺乳咨询。据Rock Health的排名，Doctor On Demand已进入成长最快的数字医疗公司前50强。</p><p><strong><em>Babylon</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B717.png" alt=""></p><p>Babylon Health创始人兼首席执行官阿里·帕尔萨</p><p>Babylon Health是一家位于伦敦的初创公司，创立于 2013 年，投资者包括DeepMind Technologies。今年4月，获得6000 万美元的 B 轮融资，这笔新融资将用于进一步提升 AI 的功能拓展，包括提供 AI 的诊断（而不是更简单的分类咨询）。公司最主要的产品是一款集合了人工智能 （聊天机器人：triage）、供用户和医疗专业人士进行视频交流、并提供相关咨询方案的 APP。</p><p><strong><em>MDlive</em></strong></p><p>主要面向企业雇主和健康计划提供商提供远程医疗服务，此外还通过智能手机应用直接面向消费者提供视频问诊服务。MDLive网络上的医生能为患者治疗的疾病主要包括过敏、哮喘、支气管炎、感冒和流感、耳部感染、尿路感染和鼻窦感染等。其已与微软结成战略联盟，利用微软的Skype for Business服务提供远程医疗服务。</p><p><strong><em>Sensely</em></strong></p><p>公司2013年成立于美国旧金山地区，由Adam Odessky(联合创始人兼CEO)、Ryan Connolly(CTO)共同创建。旗下的主要产品是一款虚拟医护APP，该应用集成大多数的医疗设备，具备语音识别、原创医疗、数据分析、身体识别、增强现实等技术。近日，该公司获得800万美元的B轮融资，有中国的成为资本、美国非盈利医疗机构梅奥诊所以及斯坦福大学的StartX创业加速器共同参投。</p><p><strong><em>Spruce</em></strong></p><p>提供异步远程医疗服务。该公司的商业模式是直接利用移动手机终端链接患者和皮肤专科医生。患者可以自己拍照或描述相关体征和感受，包括既往病史等。然后获得皮肤科医生的个性化咨询和治疗指导，24小时服务，可以网上开处方药。</p><p><strong><em>HealthTap</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B718.png" alt=""></p><p>美国的一家提供7*24小时远程问诊服务的移动医疗互联网公司，医生可以在该平台通过视频、语音或文字信息完成对病人的在线诊断、指导性治疗。而虚拟医疗正是建立在此服务平台基础之上，利用现有的科技硬件设备，比如智能手机、个人电脑、可穿戴设备等，从而完成高效、高质量的医疗健康服务。</p><p><strong><em>Call9</em></strong></p><p>一家通过视频指导现场人员展开急救行动从而提高伤者生还率的公司。去年完成了1000万美元的A轮融资。Call9的远程诊断服务将疗养院病人和急诊室医生连接起来。它还将系统设置在了疗养院中，以便为疗养院的病人提供移动设备的软件下载服务。</p><p><strong><em>Pager</em></strong></p><p>是一家面向非急救病人，为纽约市内患者提供早8点到晚10点的“按需医生服务”的远程医疗公司。由Uber首席技术官OscarSalazar Pager创立，去年完成了一笔1400万美元的融资。患者可以把“Uber医生”叫到家里或办公室进行诊治。</p><pre><code>2、糖尿病管理服务</code></pre><p><strong><em>WellDoc</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B719.png" alt=""></p><p>早在2005年就已创立的WellDoc可谓移动医疗（mHealth）的开先河者，其更体现患者的个性化监测和管理。通过了510（k）二级批准，WellDoc可以同时提供BlueStar和BlueStar Rx，从而允许公司通过更多渠道从这两个版本分析患者录入的糖尿病数据，同时与患者过去的数据进行比较得出趋势，最后形成个性化指导。</p><p><strong><em>Glooko</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B720.png" alt=""></p><p>Glooko拥有自己的血糖仪和App，与一般糖尿病管理平台不同的是，它并不是将产品直接卖给病人，而是推广给医生和诊所等医疗系统成员，再由医生们提供给患者，搜集血糖数据在对医疗系统的产品中，Glooko有population tracker，帮助医护人员快速高效的管理数个病人，检测其身体变化情况。</p><p><strong><em>Sweetch</em></strong></p><p>去年，总部位于以色列的Sweetch公司，在A轮融资中获350万美元。公司项目是一款致力于糖尿病风险诊断的软件。该软件不仅可以为潜在患者预测其患病可能，也可以令已患病却不知情的患者了解自己的病情。</p><p><strong><em>Farewell</em></strong></p><p>公司总部位于旧金山，研发的产品主要是通过解决肥胖症来达到预防慢性疾病的目的。FareWell的产品组合包括：数字化的工具、健康教练和饮食计划，这些产品都鼓励用户健康饮食，尤其鼓励食用植物类食物。</p><p><strong><em>Omada </em></strong> </p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B721.png" alt=""></p><p>Omada Health是“数字化疗法”的先锋，它将临床验证行为医学应用于治疗慢性疾病。这项程序能帮助人们克服不良习惯，以远离那些可怕但可预防的疾病。它还与企业雇主及健康计划展开合作，把重点放在高危人群上。</p><p><strong><em>Livongo</em></strong></p><p>该公司成立于2014年,开发了一种管控糖尿病的解决方案，集最新技术和指导于一体，为用户提供准确的信息以及实用的工具。3月17日，公司获得5250万美元D轮融资，由原投资人General Catalyst Partners和国际投资公司Kinnevik联合领投。</p><pre><code>3、用药管理和监测服务</code></pre><p><strong><em>AiCure</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B722.png" alt=""></p><p>管理垂直疾病领域。AiCure公司的主要产品是一款APP，可以在任何一台带有摄像头的移动设备上，利用移动技术、面部识别技术和特殊算法，来确认患者已经按时服药。2016年，该公司完成了1,225万美元的A轮融资。</p><p><strong><em>Medisafe</em></strong></p><p>Medisafe的应用程序，是以色列公司基于用药依从性的云应用系统而研发的。患者会收到MediSafe的用药提醒，随后MediSafe会提示患者在服药时记录用药量。如果程序没有显示患者服用了药物，患者的亲朋好友们就会收到通知，从而对患者采取行动。</p><p><strong><em>Chrono Therapeutics</em></strong></p><p>该公司位于加州的海沃德，它正在开发一套可以与尼古丁贴片传感器连接使用的app设备,企图用综合方法来帮助人们戒烟，将药物、数字传感器和真人教练相结合，多面“围攻”。这种方法对多种疾病的治疗或生活习惯的培养都很有借鉴意义。</p><p><strong><em>Pear Therapeutics</em></strong></p><p>美国一家数字医疗公司，成立于2013年，旨在通过数字健康与药物疗法的组合使用，来帮助患有药物滥用症、精神分裂症的患者。2016年B轮融资2000万美元。</p><pre><code>4、就诊预约管理服务</code></pre><p><strong><em>Carbon Health</em></strong></p><p>公司总部位于旧金山，成立于2015年。近日，公司获得650万美元种子轮投资，由BuildersVC领投。融资后的资金将用于继续开发数字平台，并加深与北加州提供商网络的进一步合作。它服务基层保健诊所，未来的野心是通过与网络供应商及其付款人、药房和实验室进行医疗保健服务的所有后端技术，成为最大的虚拟健康系统。</p><p><strong><em>practo </em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B723.png" alt=""></p><p>印度领先的医疗保健平台，创立于 2008 年，总部位于班加罗尔，致力于将数百万患者与世界各地数十万医疗保健机构相连接。1 月 17 日，公司宣布获得 5500 万美元 D 轮融资，由腾讯领投。公司计划利用本轮融资进一步创建一个综合医疗保健平台，发掘整个医疗生态系统的价值，并进一步投资公司国际业务。</p><pre><code>5、呼吸系统疾病监管</code></pre><p><strong><em>Cohero health</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B724.png" alt=""></p><p>一家专注于改善呼吸系统疾病患者的护理和用药情况的创业公司。CoheroHealth移动肺活量计，是FDA批准的首款此类设备，可在家庭使用，并使医生通过智能手机或者平板电脑持续追踪数据。该设备还添加了Cohero哮喘和COPD管理平台，包括带有蓝牙传感器的智能吸入设备。</p><p><strong><em>Strados Labs</em></strong></p><p>2016年创立于美国费城。Strados Labs是一个早期的科技公司,为慢性疾病管理开创更好的解决方案。该公司的旗舰产品Pulmawear,利用智能传感器和一个用户友好的移动平台，帮助患者更好地管理慢性哮喘带来日常生活挑战。用户现在可以使用数据的力量来量化他们的症状,药物,并查看病情的趋势。</p><p><strong><em>Propeller</em></strong></p><p>成立于2007年，位于威斯康星州麦迪逊市，四轮融资后，总融资额达到2840万美金。Propeller Health是一个移动平台，提供传感器，移动应用程序，分析和支持呼吸健康管理的服务，帮助哮喘和COPD患者呼吸更轻松。</p><pre><code>6、药店物流配送服务</code></pre><p><strong><em>Capsule</em></strong></p><p>Capsule是一家总部位于纽约的初创医药公司，被称为是药品版Uber。它让你不必再去类似Walgreens或者CVS这样的药店就可以买到药品，因为Capsule会把药送到你的办公室或者家里。你可以在Capsule的app中看到你的处方的信息，包括花费、药每天吃多少等等。然后你可以把药放到购物车里，选择送货的日期、时间和地址。</p><p><strong><em>Zipdrug </em></strong></p><p>提供按需送药的服务，只要动一动手指，它就可以把药送至眼前。当用户第一次使用这个App时，医生会事先把处方、价格以及使用说明都送到指定的药房，用户会根据收到的提示进入药房。然后，这个公司会派送快递员去取走你的药，这一系列的过程都是在背景核对、药物审查以及HIPAA法案的保障下安全进行。</p><p><strong><em>Pillpack</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B725.png" alt=""></p><p>提供在线订药服务的初创公司PillPack还会帮患者送药上门做更私人的用药简化服务。具体的流程是，在PillPack官网上注册账号后，系统会要求你关联到常用的处方药店，然后获取你的处方信息，将药品分装成以日为单位的简易包装。口服药品的这种包装是很像凭条的东西，事实上也是用户每日用药详情的一个提醒。</p><pre><code>7、心血管疾病管理</code></pre><p><strong><em>AlivecorAliveCor </em></strong></p><p>主要为心脏功能欠佳的用户提供产品和服务。公司推出了叫做 KardiaPro 的平台，利用人工智能帮助医生预防患者中风。KardiaPro 会追踪患者的体重、日常活动和血压等，并利用自家的人工智能技术进行梳理和对比，找到那些医生没有检查出来的潜在危险因素。近日，该公司已完成一轮 3000 万美元的融资，投资方为日本健康医疗公司欧姆龙（Omron Healthcare）和美国非盈利机构梅奥医院（Mayo Clinic）。</p><p><strong><em>Eko</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B726.png" alt=""></p><p>Eko Device制造了一个叫做Eko Core的小适配器，这个适配器是用于连接听诊器的听筒和听胸器，可以将心脏的声音通过蓝牙传输到手机上，手机应用可以将音频数据上传到云端，专家就能远程会诊了。另外，EkoCore还是首个符合HIPAA，并且支持电子健康记录的手机应用。</p><p><strong><em>Endotronix</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B727.png" alt=""></p><p>公司提供数字医疗技术解决方案，将基于云技术的病人管理系统与可植入肺动脉传感器相结合，以用于改善门诊血液动力学管理现状。这个无线解决方案无缝集成了日常临床检测的关键生理数据，可以加强患者、护理人员和医生之间的沟通，从而能够早期发现心力衰竭症状，降低心力衰竭患者住院率。2016年7月，Endotronix 宣布完成 3200 万美元 C 轮融资。</p><p><strong><em>Cardiosecur</em></strong></p><p>Personal MedSystems是一家以品牌CardioSecur闻名的德国医疗器械公司，今年2月的B轮融资536万美元（500万欧元）。CardioSecur是一款与智能手机连接的心电图（ECG）设备，适用于心脏病患者。CardioSecur提供使用四色电极的15导联心电。用户在首次接收设备时记录参考ECG，然后可以记录常规ECG并将其与参考进行比较。</p><pre><code>8、持续性健康管理</code></pre><p><strong><em>Heal</em></strong></p><p>去年10月，这家位于洛杉矶的公司获得 2690 万美元的 A 轮融资，由 Tull 投资集团领投，本轮之后，Heal 累计融资 4435 万美元，估值达到 1.1 亿美元。Heal 成立于 2014 年，其目标与许多按需医疗保健服务类似，但最大的区别在于 Heal 不再依赖视频技术问诊，而是提供上门服务。</p><p><strong><em>LumiraDx</em></strong></p><p>LumiraDx帮助实现更好的医疗保健、社会保障和财务产出，提供行之有效的解决方案实现卫生保健转换目标。其提供直观软件,拥有集成的模块化和开放的云平台，将个人与卫生和社会保健提供者的日常工作流程无缝融合。无线连接诊断设备为个人提供开创性的保健解决方案，比如糖尿病,心脏衰竭,慢性阻塞性肺病。</p><p><strong><em>Honor</em></strong></p><p>一家专注于给老年人提供到家看护服务的创业公司，A 轮融资获得 2000 万美金 ，由大名鼎鼎的 Andreessen Horowitz 领投。Honor是一家在线护理O2O预定平台，它连接了护理员、老人和老人的家庭成员三方。它解决了老年人挑选合适护理人员的需求，也使其它家庭成员能给随时知道老人的情况。</p><p><strong><em>Hometeam</em></strong></p><p>提供一种新的家庭护理方式。其iPad应用能跟踪家里发生的事情，为你打理邮件并对每日的邮件作潜在问题的标记。照顾老年人的专家和24小时的支持团队随时可以回答问题,并提供家庭帮助。</p><pre><code>9、止痛药服用和监管</code></pre><p><strong><em>Meadow</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B728.png" alt=""></p><p><strong>线上交易平台，其瞄准的是合法的</strong>交易市场，主要用户为有需求的病人和诊所/药房。目前使用工具是网页。Meadow刚启动了一个新的项目叫做CannabisMD，用户如果不明**医用使用原理，或者在使用后有任何不良反应，可以直接预约挂号，线下就有医生来看病，或者调整剂量。</p><p><strong><em>Eaze</em></strong></p><p><img src="/2018/07/08/医疗健康/" alt=""></p><p>位于旧金山的Eaze，“Uber For Weed”之一，都是将诊所、医院、药房和个人等连接起来的撮合经济平台，做的是按需消费。但Eaze不一样的是，主打卖点是顶级的诊所药房和高端消费。</p><p><strong><em>Grassp</em></strong></p><p>Grassp在病人需求与优质的医疗**产品之间建立了安全、方便的路径。Grassp技术赋予病人与顶级服务提供商交流的权力,同时为用户提供引导路径。大卫•约翰逊是公司的首席执行官和创始人，他负责监督公司的战略发展和先进的企业交叉技术平台扩张。在数据管理和应用技术解决方案上有超过10年的经验。</p><pre><code>10、儿童疾病监管</code></pre><p><strong><em>Kinsa</em></strong></p><p><img src="file:///D:/%E6%9C%89%E9%81%93%E4%BA%91%E7%AC%94%E8%AE%B0/hanzf100@163.com/377ce9967e46449cb9eddc672214ade6/877049133701.png" alt=""></p><p>智能体温计Kinsa可以一端含于嘴中测量体温（也可以夹在腋下或是测肛温），另一端可以通过数据线或者是直接接入手机的3.5毫米接口。测量十秒后，测量者的体温便会被显示在手机上。值得一提的是，Kinsa会在十秒的测量间隙用动画来保持孩子的注意力，让他们不会因为太无聊而对测体温感到厌烦。</p><p><strong><em>Owlet</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B731.png" alt=""></p><p>公司生产的微型婴儿智能袜在睡觉时穿着，能够追踪心率、皮肤温度、血氧和睡眠数据，然后上传到云端，父母利用智能手机上的 iOS 和 Android 客户端，或者通过门户网站即可获取。袜子上装有可充电电池，电量低时就会通过智能手机向父母发出警报。</p><p><strong><em>Cognoa</em></strong></p><p>公司总部位于加州帕洛阿尔托，属于创业热地，主营业务是一个用于评估儿童健康成长的应用。近日获得1160万美元风险投资，由现有投资者Morningside领投，目前公司总融资额达到2000万美元。此轮融资资金，主要用于对FDA提交的路径进行额外的验证研究，并且扩大儿科医生，企业雇主以及保险公司的销售渠道。</p><pre><code>11、女性健康管理</code></pre><p><strong><em>Clue</em></strong></p><p>公司于 2013 年在柏林成立，致力于通过应用程序提供女性排卵期的相关数据，目前超过 500 万用户在 Clue 的应用程序上通过身体数据关注自己的情绪变化或者查看自己是否处于情绪状态。该应用程序对于妇科症状的解释引用了欧美最新的医学文献。</p><p><strong><em>Lucina</em></strong></p><p>Lucina Health，公司总部设在肯塔基州的路易斯维尔，其使命是通过一流的保健与及时的深度早产分析，帮助减少早产。利用聚合数据的力量和深度产科分析，Lucina从根本上改变了护理管理方式，来减少早产和相关成本。Lucina的数据平台Firefly,对风险、环境和妊娠并发症进行了深刻评估。结合Firefly,MyLucina 是一款面向妈妈群体的移动应用,为每个病人提供个性化的宣传和教育。</p><p><strong><em>Nurx</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B732.png" alt=""></p><p>美国加州医疗公司Nurx试图在规则内，利用app开具避孕处方，并按需求进行配送，解决种种不便。用户不必去医院或者药店，在线可以获得避孕服务。其变革性的技术改变了人们接触卫生保健的方式，利用消息传递平台、移动应用、机器人和嵌入式系统降低成本和简化病人体验。</p><pre><code>12、精神心理咨询管理</code></pre><p><strong><em>Big health</em></strong></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B733.png" alt=""></p><p>公司致力于提供“实证、非药物”解决方案，以应对各种精神健康障碍。公司通过追踪用户数据，创建个性化的数字程序，用户能够随时通过网络或手机获取到行为解决方案，不分昼夜。公司首款产品 Sleepio 是一个数字睡眠改善程序，来帮助用户克服睡眠问题，并在这一过程中改善他们的心理健康状况。</p><p><strong><em>Silvercloud</em></strong></p><p>英国公司SilverCloud Health的技术可以帮助患者在出了诊疗室后，继续治疗。SilverCloud开发的产品是让真正的诊疗师去使用，所以当患者出了诊疗室之后，还可以有机会和医师进行互动，获得治疗建议。其提供的患者康复和参与度的比率，与传统的面对面疗法一致。</p><p><strong><em>Talkspace</em></strong></p><p>作为领先的在线治疗公司，Talkspace通过在治疗师与其客户之间建立沟通的平台，将二者的对话带入数字时代，改变了精神疾病的诊疗方式。该公司在成立之初，就立下使命，要根除人们与精神疾病相关的耻辱感，让数百万人能接受治疗。Talkspace的旗舰产品：无限信息疗法，已被超过300,000的人试用。</p><p><strong><em>Akili</em></strong></p><p>Akili Interactive，属于生物科技公司PureTech，正在做治疗神经系统疾病的手机游戏。去年7月，B轮总融资额高达7290万美元。公司的龙头产品——Project Evo游戏，是用来训练多动症儿童的，让他们给大堆信息排出先后次序，以此来提升专注度。</p><p><strong><em>Lyra</em></strong></p><p>公司正在建立一个由数据驱动的平台，来识别有行为和精神健康状况风险的人。Lyra Health有着不同的部门，来对可能需要心理健康支持的人进行评估。它为初级护理的提供者提供数字诊断测试。这些测试用来对病人进行筛选和评估，确定潜在的需要接受行为健康护理的患者。</p><h4 id="五、总结展望"><a href="#五、总结展望" class="headerlink" title="五、总结展望"></a>五、总结展望</h4><blockquote><p>新技术形成新的生产力，升级医疗行业</p></blockquote><p>现代科学技术的发展已经到了一个非常重要的时期。科学技术化、技术科学化、科学技术社会化、社会科学技术化的浪潮正以前所未有的方式冲击着当今世界的各个领域。</p><p>科学技术信息系统的复制与表达对人类社会政治、经济、文化、生活的影响是极其深远的。它就像基因一样决定了人类社会文明发展的各个方面。科学技术的每一次重大突破对人类社会政治、经济、文化都将产生巨大的影响。科学技术革命对人类社会的生产力、生产关系、经济基础、上层建筑的变革具有极其重要的作用。科学技术创新已经成为人类社会文明进化发展的根本源动力。</p><p>经济包括生产、交换、分配、消费等环节，以生产为核心。科学技术与经济的关系首先是科学技术与生产的关系。科学技术同其他调节生产关系效率的各种工具有着本质的差别，他以创造生产力的方式，对现有生产要素进行升级或替代。</p><p>在医疗领域，提高人类对生命的认知是科学技术的起点和归宿，科技创新是最活跃、最积极的生产力因素。只有通过科技创新，生产力效率才能更好更积极地发挥出来。</p><p>数字医疗1.0 时代，互联网技术打破了医学知识壁垒，医学知识分享平台和连接医患的诊疗平台受到资本的热捧。移动医疗2.0 时代，面向医疗核心的技术革新成为了今年的趋势，其中基因检测和人工智能的快速产业化发展显得尤为突出。</p><p>前几年的数字医疗领域主要集中在颠覆就医流程的服务创新方面。今年，人工智能、辅助决策、医疗大数据、基因等领域频频迎来大额融资，以技术创新带来的医疗变革的序幕已经拉开。接下来，将有更多的黑科技加入到诊疗中来，为我们带来更多的生命奇迹。</p><p><img src="http://vcbeat.net/upload/image/08/12/11/34/1512981254768165.png" alt=""></p><p><img src="http://vcbeat.net/upload/image/08/12/11/34/1512981261276838.png" alt=""></p><p><img src="http://vcbeat.net/upload/image/08/12/11/34/1512981268187394.png" alt=""></p><p><img src="http://vcbeat.net/upload/image/08/12/11/34/1512981277675922.png" alt=""></p><blockquote><p>生产关系改变：从竞争到协作，医疗机构的差异化新格局</p></blockquote><p>改革开放以来，我国多个行业通过市场化改造，引入了市场竞争机制。但医疗健康行业不同于其他行业。医疗行业并不是为了通过市场化竞争创造商业价值，而是以保障居民健康，提高人民福祉为本位。同时，医疗健康产业在造福国民生活，维持国家安定和谐起着举足轻重的作用。这就意味着，我国医疗健康行业，一定是以公有制为主导的行业。</p><p>以公有制为主导，并不意味着医疗健康行业，不会受到市场经济客观规律的影响, 尤其是在国民需求快速增长，国内市场化程度、经济自由度日益增加的今天。这个规律就包括竞争理论。在竞争理论中，行业的弱势竞争者，只有拥有先发优势或通过创造差异化价值，才可能在竞争中获胜。而同时，公有制为主导的行业参与者，往往缺乏商业化的战略思考，造成竞争战略的缺失。</p><p>个体的理性选择，往往会造成群体的非理性选择。从医疗机构竞争格局的角度来讲，这样的理性选择意味着，各种竞争实力完全不对等的医疗机构，服务严重重叠，而服务价格基本相同。这意味着拥有竞争力的医疗机构将门庭若市，缺乏竞争力医疗机构则门可罗雀。</p><p>另一方面，马太效应使得医疗行业产生了 “消费集中→大医院竞争力变强→消费被吸引→大医院竞争力变强”的恶性循环。对于一般的行业而言，这是正常的行业整合过程，这个过程实现了市场参与者的优胜劣汰，是行业发展的必经之路。我国的医疗健康行业以保障人民生活为本位，优胜劣汰的丛林法则注定无法被适用，因此，马太效应反而加剧了我国医疗服务的不均衡，降低了行业生产力，产生了强者愈强、弱者愈弱的恶性循环。</p><p>我们可以认为，国内医疗资源不均衡的问题本质，就是医疗机构间的同质化竞争格局。纵观国内近几年的医改思路，我们会发现这些政策的背后，大都有一个逻辑：赋予不同医疗机构不同的服务职能，从而实现差异化定位；提高弱势医疗机构竞争力，促使消费下沉。在医疗机构间，建立“相互补充、合作共赢”的医疗健康行业新生产关系。</p><p>以近几年的医改核心分级诊疗为例，“分级”这个词本身，就充满了“差异化”的味道，将原本的同质化业务拆分成数个单元，分别对应在不同级别竞争力的医疗服务供应商上。</p><p>分级诊疗，从个人健康需求本位出发，将需求按照“轻、重、缓、急”进行疏导，同时分解医疗过程。结合被拆解的个人需求与医疗过程，将不同竞争力医疗机构的核心职能进行重新定义，从而实现分级诊疗，建立差异化行业分工合作格局。从本质上讲，分级诊疗是我国医疗行业分工的深化，是对我国医疗行业生产关系的重构。</p><p><img src="http://vcbeat.net/upload/image/08/12/11/39/1512981540675659.png" alt=""></p><blockquote><p>生产要素的改变：从医院到医生，品牌效应在转移</p></blockquote><p>在国内医疗体系中，医院毫无疑问是诊断和治疗疾病的最重要场所，也是承载所有医疗行为的地方。在现代化医院管理进程中，随着医院的发展与壮大，只有创建出好的医院品牌，才能不断提升医院的核心竞争力。</p><p>医院和医生，是两个相辅相成的医疗生产要素。在过去，人们对医疗品牌的认知主要是在医院。这里的医院，主要是指公立三甲医院。医院的品牌和专科、专家的技术实力息息相关，能诊治别人诊治不了专科疾病，并取得了同行与社会认可。医院的品牌效应不但能吸引病人的到来，也吸引了人才的加入以及更多资源的投入，使医院在激烈的市场竞争中立于不败之地。</p><p>一个好的医生虽然是医院品牌建设过程中的重要名片，打造明星专家就是为医院品牌打下基石。但是在之前，医院是名医的唯一归宿与展示平台。现在，随着民营医院、医生集团、民营诊所和互联网平台的发展，使得医生有了更多的发展空间和平台。</p><p>以前，医生品牌很难摆脱医院这个大庙。在互联网时代，一名医生要塑造自己的品牌需要在三个方面努力：学科品牌、个人服务品牌、社会影响力。</p><p>诸如张强、于莺、崔玉涛等医生，通过在互联网平台的耕耘，形成了甚至不弱于医院的医生品牌。他们在互联网平台上进行医疗方面的科普，和患者进行互动，吸引了大量的粉丝。这些“网红医生”依靠自己的品牌，就能吸引到足够多的患者，无论他们的执业平台是在医生集团、民营医院还是自营诊所。</p><p>医疗的品牌效应，已经逐渐在从医院往医生身上在转移，还出现了除公立医院外的其他医疗场所来承载医生的医疗行为，包括民营医院、互联网医院、共享医院、诊所等。</p><p><img src="http://vcbeat.net/upload/image/08/12/11/41/1512981687236867.png" alt=""></p><p><img src="http://vcbeat.net/upload/image/08/12/11/41/1512981696888650.png" alt=""></p><p><img src="http://vcbeat.net/upload/image/08/12/11/41/1512981702954890.png" alt=""></p><blockquote><p>消费观念的升级：消费需求提升，倒逼医疗行业市场化</p></blockquote><p>中国医疗行业的市场化之辩一直存在。</p><p>医疗市场化的鼓吹者认为，通过借鉴以美国为代表的市场化医疗体系，能够提升中国医疗产品和医疗服务的整体质量，进而优化中国医疗资源的配置。而医疗市场化的反对者认为，政府一直是中国医疗资源分配的指挥者，能够让医疗资源以一种较低的成本分配到需要它的患者手中，公益属性应该是医疗的第一属性，而这也是目前最能体现我国医疗体制优越性的地方。</p><p>争论仍然在继续，但是市场已经开始出现微妙的变化——种种迹象表明，中国医疗行业的市场化之路似乎已经不再是可有可无的自主选择，而是需求倒逼的必然结果。</p><p>首先，对于政府部门来说，多地已经出现医保账户见底的预警，“控费”成为悬挂在医疗相关部门头顶的一把达摩克斯之剑。而通过市场化的手段，鼓励社会资本和社会资源进入医疗行业无疑会极大缓解政府面临的财政压力。</p><p>透过国家卫生和计生委公布的年度卫生年鉴，我们能够清晰地看到民营资本正在壮大——民营医疗机构的数量已经在2015 年底超过公立医疗机构，并且这种“民进国退”的趋势仍在延续。</p><p>与此同时，中国不断壮大的中产阶级，以及各行各业热议的“消费升级”现象，正在深刻影响中国医疗健康产业。口腔、眼科、医美等消费类医疗项目在资本市场受到的热情追捧正是这种大背景的一个缩影。</p><p>中国的分级诊疗可以说既是政府的一种倡导，实际上也是一种客观的时代趋势。中国医疗产业似乎也到了一个类似的临界点——让部分有需求的患者自费享受优质的医疗资源，政府兜底百姓的基础医疗需求。</p><p>无论是基本的全科，还是高精尖的肿瘤专科。无论是高楼耸立的北上广深，还是仍在缓慢发展中的三四线城市。医疗行业的市场化现象已经不仅仅局限在某个区域或者某些服务，它是在行业中都在蔓延的一种趋势。</p><p>蛋壳研究院选取了需求倒逼医疗行业市场化最突出的两大行业——母婴行业和医药流通行业，从资源的自由选择和资本的自由选择，透过它们在2017 年的发展和演变，一起探索中国医疗行业市场化的方向。</p><p><img src="http://vcbeat.net/upload/image/08/12/11/44/1512981867911894.png" alt=""></p><p><img src="http://vcbeat.net/upload/image/08/12/11/44/1512981874751352.png" alt=""></p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;探索生命的更多可能性&quot;&gt;&lt;a href=&quot;#探索生命的更多可能性&quot; class=&quot;headerlink&quot; title=&quot;探索生命的更多可能性&quot;&gt;&lt;/a&gt;探索生命的更多可能性&lt;/h3&gt;&lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://p6ux47i4n.bkt.clouddn.com/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B7.jpg&quot; alt=&quot;yiliaojiankang.jpg&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;/p&gt;
&lt;h4 id=&quot;一、市场容量及趋势&quot;&gt;&lt;a href=&quot;#一、市场容量及趋势&quot; class=&quot;headerlink&quot; title=&quot;一、市场容量及趋势&quot;&gt;&lt;/a&gt;一、市场容量及趋势&lt;/h4&gt;&lt;p&gt;前瞻产业研究院数据显示，2016年，中国的医疗健康产业市场规模接近3万亿元;据《“健康中国2020”战略规划》、《“健康中国2030”战略规划》，健康服务业的总规模到2020年要做到八万亿，2030年要达到&lt;strong&gt;十六万亿&lt;/strong&gt;。医疗健康目前是美国最赚钱的行业，在投资回报率、收益率等方面也都排在第一。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="医疗健康" scheme="https://zhenfenghan.github.io/tags/%E5%8C%BB%E7%96%97%E5%81%A5%E5%BA%B7/"/>
    
      <category term="AI医疗" scheme="https://zhenfenghan.github.io/tags/AI%E5%8C%BB%E7%96%97/"/>
    
      <category term="移动医疗" scheme="https://zhenfenghan.github.io/tags/%E7%A7%BB%E5%8A%A8%E5%8C%BB%E7%96%97/"/>
    
  </entry>
  
  <entry>
    <title>飞越喜马拉雅</title>
    <link href="https://zhenfenghan.github.io/2018/05/20/%E5%8A%A0%E5%BE%B7%E6%BB%A1%E9%83%BD/"/>
    <id>https://zhenfenghan.github.io/2018/05/20/加德满都/</id>
    <published>2018-05-20T02:01:11.000Z</published>
    <updated>2018-05-23T13:34:10.732Z</updated>
    
    <content type="html"><![CDATA[<p><strong>光明之城–加德满都之行</strong><br><img src="http://p6ux47i4n.bkt.clouddn.com/psb87I0LGLO.jpg" alt="galance.jpg"><br>加德满都是尼泊尔首都，位于加德满都谷地，巴格马提河和比兴马提河的汇口处。该市四周环山。北以喜马拉雅山为屏，南向印度洋暖流，海拔1370米。四季如春，气侯宜人，年平均温度20℃左右，素有“山中天堂”的美称。是世界闻名的游览胜地。  </p><p>加德满都是一座拥有1000多年历史的古老城市，它以精美的建筑艺术、木石雕刻而成为尼泊尔古代文化的象征。尼泊尔历代王朝在这里修建了数目众多的宫殿、庙宇、宝塔、殿堂和寺院等建筑，在面积不到7平方公里的市中心有佛塔、庙宇250多座，全市有大小寺庙2700多座，真可谓“五步一庙、十步一庵”，因此，有人把这座城市称为“寺庙之城”、“露天博物馆”。<br><a id="more"></a></p><p><img src="http://p6ux47i4n.bkt.clouddn.com/psbXV8ANAT8.jpg" alt="airport.jpg"><br><img src="http://p6ux47i4n.bkt.clouddn.com/psbZUH1DU7B.jpg" alt="littlegirl.jpg"><br><img src="http://p6ux47i4n.bkt.clouddn.com/psbS5DSO1ZY.jpg" alt="bookhouse.jpg"><br><img src="http://p6ux47i4n.bkt.clouddn.com/psbDMWU6LZH.jpg" alt="buddaeye.jpg"><br><img src="http://p6ux47i4n.bkt.clouddn.com/psbJDO9W6VM.jpg" alt="buddaeye2.jpg"><br><img src="http://p6ux47i4n.bkt.clouddn.com/psbRP3P0T8B.jpg" alt="chengdu.jpg"><br><img src="http://p6ux47i4n.bkt.clouddn.com/psbV11UIR4T.jpg" alt="yoga.jpg"><br><img src="http://p6ux47i4n.bkt.clouddn.com/psbEL3D88UF.jpg" alt="yoga.jpg"><br><img src="http://p6ux47i4n.bkt.clouddn.com/psbOC5CFBUA.jpg" alt="beauty.jpg"><br><img src="http://p6ux47i4n.bkt.clouddn.com/psb0X4DR5YN.jpg" alt="danceclub.jpg"><br><img src="http://p6ux47i4n.bkt.clouddn.com/psbIDNVHCIV.jpg" alt="duba.jpg"><br><img src="http://p6ux47i4n.bkt.clouddn.com/psbMU4WE91B.jpg" alt="friends.jpg"><br><img src="http://p6ux47i4n.bkt.clouddn.com/psb520Y94A1.jpg" alt="friends.jpg"><br><em>文字记录稍后添加~</em></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;光明之城–加德满都之行&lt;/strong&gt;&lt;br&gt;&lt;img src=&quot;http://p6ux47i4n.bkt.clouddn.com/psb87I0LGLO.jpg&quot; alt=&quot;galance.jpg&quot;&gt;&lt;br&gt;加德满都是尼泊尔首都，位于加德满都谷地，巴格马提河和比兴马提河的汇口处。该市四周环山。北以喜马拉雅山为屏，南向印度洋暖流，海拔1370米。四季如春，气侯宜人，年平均温度20℃左右，素有“山中天堂”的美称。是世界闻名的游览胜地。  &lt;/p&gt;
&lt;p&gt;加德满都是一座拥有1000多年历史的古老城市，它以精美的建筑艺术、木石雕刻而成为尼泊尔古代文化的象征。尼泊尔历代王朝在这里修建了数目众多的宫殿、庙宇、宝塔、殿堂和寺院等建筑，在面积不到7平方公里的市中心有佛塔、庙宇250多座，全市有大小寺庙2700多座，真可谓“五步一庙、十步一庵”，因此，有人把这座城市称为“寺庙之城”、“露天博物馆”。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="随笔" scheme="https://zhenfenghan.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
      <category term="加德满都" scheme="https://zhenfenghan.github.io/tags/%E5%8A%A0%E5%BE%B7%E6%BB%A1%E9%83%BD/"/>
    
      <category term="旅行" scheme="https://zhenfenghan.github.io/tags/%E6%97%85%E8%A1%8C/"/>
    
  </entry>
  
  <entry>
    <title>分类性能度量指标--ROC、AUC</title>
    <link href="https://zhenfenghan.github.io/2018/05/04/ROC,AUC/"/>
    <id>https://zhenfenghan.github.io/2018/05/04/ROC,AUC/</id>
    <published>2018-05-04T01:01:11.000Z</published>
    <updated>2018-05-04T12:39:54.396Z</updated>
    
    <content type="html"><![CDATA[<p>在分类任务中，人们总是喜欢基于错误率来衡量分类器任务的成功程度。错误率指的是在所有测试样例中错分的样例比例。实际上，这样的度量错误掩盖了样例如何被分错的事实。在机器学习中，有一个普遍适用的称为混淆矩阵(<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Confusion_matrix" target="_blank" rel="noopener">confusion matrix</a>)的工具，它可以帮助人们更好地了解分类中的错误。</p><p>比如有这样一个在房子周围可能发现的动物类型的预测，这个预测的三类问题的混淆矩阵如下表所示：</p><p><img src="https://upload-images.jianshu.io/upload_images/145616-dcd144da21bdc9b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/403" alt=""></p><p>一个三类问题的混淆矩阵</p><p>利用混淆矩阵可以充分理解分类中的错误了。如果混淆矩阵中的非对角线元素均为0，就会得到一个近乎完美的分类器。</p><p>在接下来的讨论中，将以经典的二分类问题为例，对于多分类类比推断。</p><p>二分类问题在机器学习中是一个很常见的问题，经常会用到。<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Receiver_operating_characteristic" target="_blank" rel="noopener">ROC</a> (Receiver Operating Characteristic) 曲线和 <a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" target="_blank" rel="noopener">AUC</a> (Area Under the Curve) 值常被用来评价一个二值分类器 (<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Binary_classification" target="_blank" rel="noopener">binary classifier</a>) 的优劣。之前做医学图像计算机辅助肺结节检测时，在评定模型预测结果时，就用到了ROC和AUC，这里简单介绍一下它们的特点，以及更为深入地，讨论如何作出ROC曲线图和计算AUC值。<br><a id="more"></a></p><h2 id="一、医学图像识别二分类问题"><a href="#一、医学图像识别二分类问题" class="headerlink" title="一、医学图像识别二分类问题"></a>一、医学图像识别二分类问题</h2><p>针对一个二分类问题，我们将实例分成<strong>正类</strong>(positive)和<strong>负类</strong>(negative)两种。</p><p>例如：在肺结节计算机辅助识别这一问题上，一幅肺部CT图像中有肺结节被认为是<strong>阳性</strong>(positive)，没有肺结节被认为是<strong>阴性</strong>(negative)。对于部分有肺结节的示意图如下：</p><p><img src="https://upload-images.jianshu.io/upload_images/145616-4bb34ffdcf31bdc1.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt=""></p><p>常见肺结节示意图</p><p>所以在实际检测时，就会有如下四种情况：</p><blockquote><p>(1) 真阳性(True Positive，TP)：检测有结节，且实际有结节；正确肯定的匹配数目；<br>(2) 假阳性(False Positive，FP)：检测有结节，但实际无结节；误报，给出的匹配是不正确的；<br>(3) 真阴性(True Negative，TN)：检测无结节，且实际无结节；正确拒绝的非匹配数目；<br>(4) 假阴性(False Negative，FN)：检测无结节，但实际有结节；漏报，没有正确找到的匹配的数目。</p></blockquote><p>详细图解（原创，转载请标明出处）如下：</p><p><img src="https://upload-images.jianshu.io/upload_images/145616-0a7a7fd1ff77dcd9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt=""></p><p>更多参数详细信息及其意义请参考 Wikipedia -&gt; <a href="https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Confusion_matrix" target="_blank" rel="noopener">Confusion_matrix</a>.</p><p>上图中涉及到很多相关概念及参数，详细请见Wiki上的<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Definitions" target="_blank" rel="noopener">定义</a>及其<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Confusion_matrix" target="_blank" rel="noopener">混淆矩阵</a>，这里整理肺结节识别中的几个主要参数指标如下：</p><ul><li>正确率(<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Precision_and_recall#Precision" target="_blank" rel="noopener">Precision</a>)：</li></ul><p><img src="http://latex.codecogs.com/png.latex?Precision=%5Cfrac%7BTP%7D%7BTP+FP%7D" alt=""></p><ul><li>真阳性率(True Positive Rate，<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Sensitivity_and_specificity" target="_blank" rel="noopener">TPR</a>)，灵敏度(<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Sensitivity" target="_blank" rel="noopener">Sensitivity</a>)，召回率(<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Precision_and_recall#Recall" target="_blank" rel="noopener">Recall</a>)：</li></ul><p><img src="http://latex.codecogs.com/png.latex?Sensitivity=Recall=TPR=%5Cfrac%7BTP%7D%7BTP+FN%7D" alt=""></p><ul><li>真阴性率(True Negative Rate，<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Sensitivity_and_specificity" target="_blank" rel="noopener">TNR</a>)，特异度(<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Sensitivity_and_specificity#Specificity" target="_blank" rel="noopener">Specificity</a>)：</li></ul><p><img src="http://latex.codecogs.com/png.latex?Specificity=TNR=%5Cfrac%7BTN%7D%7BFP+TN%7D" alt=""></p><ul><li>假阴性率(False Negatice Rate，<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/False_positives_and_false_negatives#False_positive_and_false_negative_rates" target="_blank" rel="noopener">FNR</a>)，漏诊率( = 1 - 灵敏度)：</li></ul><p><img src="http://latex.codecogs.com/png.latex?FNR=%5Cfrac%7BFN%7D%7BTP+FN%7D" alt=""></p><ul><li>假阳性率(False Positice Rate，<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/False_positive_rate" target="_blank" rel="noopener">FPR</a>)，误诊率( = 1 - 特异度)：</li></ul><p><img src="http://latex.codecogs.com/png.latex?FPR=%5Cfrac%7BFP%7D%7BFP+TN%7D" alt=""></p><ul><li><p><a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing#positive_likelihood_ratio" target="_blank" rel="noopener">阳性似然比</a> = 真阳性率 / 假阳性率 = 灵敏度 / (1 - 特异度)</p></li><li><p><a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Likelihood_ratios_in_diagnostic_testing#negative_likelihood_ratio" target="_blank" rel="noopener">阴性似然比</a> = 假阴性率 / 真阴性率 = (1 - 灵敏度) / 特异度</p></li><li><p><a href="https://link.jianshu.com/?t=http://baike.baidu.com/link?url=ocB5vtVDdo5gYlDxy3xlonrDGQUTZVNv3_uK3FRE30qVYsTeeXPif3fEbQSw2-IZzEoseco7zo-WVEnXM2rngLNp-e2xSej_cUfT6a3afELWFUmvrLtZIKfwMOFNCbKG" target="_blank" rel="noopener">Youden指数</a> = 灵敏度 + 特异度 - 1 = 真阳性率 - 假阳性率</p></li></ul><h2 id="二、ROC曲线"><a href="#二、ROC曲线" class="headerlink" title="二、ROC曲线"></a>二、ROC曲线</h2><p><strong>ROC曲线</strong>：接收者操作特征曲线（<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Receiver_operating_characteristic" target="_blank" rel="noopener">receiver operating characteristic curve</a>），是反映敏感性和特异性连续变量的综合指标，roc曲线上每个点反映着对同一信号刺激的感受性。</p><p>对于分类器，或者说分类算法，评价指标主要有precision，recall，F-score等，以及这里要讨论的ROC和AUC。下图是一个ROC曲线的示例：</p><p><img src="https://upload-images.jianshu.io/upload_images/145616-651daa43e80f4c8f.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/500" alt=""></p><ul><li>横坐标：<strong>1-Specificity</strong>，伪正类率(False positive rate， FPR)，<strong>预测为正但实际为负</strong>的样本占<strong>所有负例样本</strong>的比例；</li><li>纵坐标：<strong>Sensitivity</strong>，真正类率(True positive rate， TPR)，<strong>预测为正且实际为正</strong>的样本占<strong>所有正例样本</strong>的比例。</li></ul><p>在一个二分类模型中，假设采用逻辑回归分类器，其给出针对每个实例为正类的概率，那么通过设定一个阈值如0.6，概率大于等于0.6的为正类，小于0.6的为负类。对应的就可以算出一组(FPR,TPR)，在平面中得到对应坐标点。随着阈值的逐渐减小，越来越多的实例被划分为正类，但是这些正类中同样也掺杂着真正的负实例，即TPR和FPR会同时增大。阈值最大时，对应坐标点为(0,0)，阈值最小时，对应坐标点(1,1)。</p><p>如下面这幅图，(a)图中实线为ROC曲线，线上每个点对应一个阈值。</p><p><img src="https://upload-images.jianshu.io/upload_images/145616-ce8221a29d9c01ef.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt=""></p><p>ROC曲线和它相关的比率</p><p>(a) 理想情况下，TPR应该接近1，FPR应该接近0。ROC曲线上的每一个点对应于一个threshold，对于一个分类器，每个threshold下会有一个TPR和FPR。比如Threshold最大时，TP=FP=0，对应于原点；Threshold最小时，TN=FN=0，对应于右上角的点(1,1)。<br>(b) P和N得分不作为特征间距离d的一个函数，随着阈值theta增加，TP和FP都增加。</p><ul><li>横轴FPR：1-TNR，1-Specificity，FPR越大，预测正类中实际负类越多。</li><li>纵轴TPR：Sensitivity(正类覆盖率)，TPR越大，预测正类中实际正类越多。</li><li>理想目标：TPR=1，FPR=0，即图中(0,1)点，故ROC曲线越靠拢(0,1)点，越偏离45度对角线越好，Sensitivity、Specificity越大效果越好。</li></ul><p>随着阈值threshold调整，ROC坐标系里的点如何移动可以参考：</p><p><img src="https://upload-images.jianshu.io/upload_images/145616-4d27c75e229c1f84.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/361" alt=""></p><h2 id="三、如何画ROC曲线"><a href="#三、如何画ROC曲线" class="headerlink" title="三、如何画ROC曲线"></a>三、如何画ROC曲线</h2><p>对于一个特定的分类器和测试数据集，显然只能得到一个分类结果，即一组FPR和TPR结果，而要得到一个曲线，我们实际上需要一系列FPR和TPR的值，这又是如何得到的呢？我们先来看一下Wikipedia上对ROC曲线的<a href="https://link.jianshu.com/?t=http://en.wikipedia.org/wiki/Receiver_operating_characteristic" target="_blank" rel="noopener">定义</a>：</p><blockquote><p>In signal detection theory, a receiver operating characteristic (ROC), or simply ROC curve, is a graphical plot which illustrates the performance of a binary classifier system as its discrimination threshold is varied.</p></blockquote><p>问题在于“as its discrimination threashold is varied”。如何理解这里的“discrimination threashold”呢？我们忽略了分类器的一个重要功能“概率输出”，即表示分类器认为某个样本具有多大的概率属于正样本（或负样本）。通过更深入地了解各个分类器的内部机理，我们总能想办法得到一种概率输出。通常来说，是将一个实数范围通过某个变换映射到(0,1)区间。</p><p>假如我们已经得到了所有样本的概率输出（属于正样本的概率），现在的问题是如何改变“discrimination threashold”？我们根据每个测试样本属于正样本的概率值从大到小排序。下图是一个示例，图中共有20个测试样本，“Class”一栏表示每个测试样本真正的标签（p表示正样本，n表示负样本），“Score”表示每个测试样本属于正样本的概率。</p><p><img src="https://upload-images.jianshu.io/upload_images/145616-ca9d12fa24fe2842.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/700" alt=""></p><p>接下来，我们从高到低，依次将“Score”值作为阈值threshold，当测试样本属于正样本的概率大于或等于这个threshold时，我们认为它为正样本，否则为负样本。举例来说，对于图中的第4个样本，其“Score”值为0.6，那么样本1，2，3，4都被认为是正样本，因为它们的“Score”值都大于等于0.6，而其他样本则都认为是负样本。每次选取一个不同的threshold，我们就可以得到一组FPR和TPR，即ROC曲线上的一点。这样一来，我们一共得到了20组FPR和TPR的值，将它们画在ROC曲线的结果如下图：</p><p><img src="https://upload-images.jianshu.io/upload_images/145616-2063bb79c3684a8a.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/632" alt=""></p><p>当我们将threshold设置为1和0时，分别可以得到ROC曲线上的(0,0)和(1,1)两个点。将这些(FPR,TPR)对连接起来，就得到了ROC曲线。当threshold取值越多，ROC曲线越平滑。</p><p>其实，我们并不一定要得到每个测试样本是正样本的概率值，只要得到这个分类器对该测试样本的“评分值”即可（评分值并不一定在(0,1)区间）。评分越高，表示分类器越肯定地认为这个测试样本是正样本，而且同时使用各个评分值作为threshold。我认为将评分值转化为概率更易于理解一些。</p><h2 id="四、AUC"><a href="#四、AUC" class="headerlink" title="四、AUC"></a>四、AUC</h2><h3 id="AUC值的计算"><a href="#AUC值的计算" class="headerlink" title="AUC值的计算"></a>AUC值的计算</h3><p>AUC (<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" target="_blank" rel="noopener">Area Under Curve</a>) 被定义为ROC曲线下的面积，显然这个面积的数值不会大于1。又由于ROC曲线一般都处于y=x这条直线的上方，所以AUC的取值范围一般在0.5和1之间。使用AUC值作为评价标准是因为很多时候ROC曲线并不能清晰的说明哪个分类器的效果更好，而作为一个数值，对应AUC更大的分类器效果更好。</p><p>AUC的计算有两种方式，梯形法和ROC AUCH法，都是以逼近法求近似值，具体见<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve" target="_blank" rel="noopener">wikipedia</a>。</p><h3 id="AUC意味着什么"><a href="#AUC意味着什么" class="headerlink" title="AUC意味着什么"></a>AUC意味着什么</h3><p>那么AUC值的含义是什么呢？根据(Fawcett, 2006)，AUC的值的含义是：</p><blockquote><p>The AUC value is equivalent to the probability that a randomly chosen positive example is ranked higher than a randomly chosen negative example.</p></blockquote><p>这句话有些绕，我尝试解释一下：首先AUC值是一个概率值，当你随机挑选一个正样本以及一个负样本，当前的分类算法根据计算得到的Score值将这个正样本排在负样本前面的概率就是AUC值。当然，AUC值越大，当前的分类算法越有可能将正样本排在负样本前面，即能够更好的分类。</p><p>从AUC判断分类器（预测模型）优劣的标准：</p><ul><li>AUC = 1，是完美分类器，采用这个预测模型时，存在至少一个阈值能得出完美预测。绝大多数预测的场合，不存在完美分类器。</li><li>0.5 &lt; AUC &lt; 1，优于随机猜测。这个分类器（模型）妥善设定阈值的话，能有预测价值。</li><li>AUC = 0.5，跟随机猜测一样（例：丢铜板），模型没有预测价值。</li><li>AUC &lt; 0.5，比随机猜测还差；但只要总是反预测而行，就优于随机猜测。</li></ul><p>三种AUC值示例：</p><p><img src="https://upload-images.jianshu.io/upload_images/145616-e04823375fb30749.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/568" alt=""></p><p>简单说：<strong>AUC值越大的分类器，正确率越高</strong>。</p><h3 id="为什么使用ROC曲线"><a href="#为什么使用ROC曲线" class="headerlink" title="为什么使用ROC曲线"></a>为什么使用ROC曲线</h3><p>既然已经这么多评价标准，为什么还要使用ROC和AUC呢？因为ROC曲线有个很好的特性：当测试集中的正负样本的分布变化的时候，ROC曲线能够保持不变。在实际的数据集中经常会出现类不平衡（class imbalance）现象，即负样本比正样本多很多（或者相反），而且测试数据中的正负样本的分布也可能随着时间变化。下图是ROC曲线和<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Precision_and_recall" target="_blank" rel="noopener">Precision-Recall</a>曲线的对比：</p><p><img src="https://upload-images.jianshu.io/upload_images/145616-a55d1493f5f26d5c.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/624" alt=""></p><p>在上图中，(a)和(c)为ROC曲线，(b)和(d)为Precision-Recall曲线。(a)和(b)展示的是分类其在原始测试集（正负样本分布平衡）的结果，(c)和(d)是将测试集中负样本的数量增加到原来的10倍后，分类器的结果。可以明显的看出，ROC曲线基本保持原貌，而Precision-Recall曲线则变化较大。</p><h3 id="Reference"><a href="#Reference" class="headerlink" title="Reference"></a>Reference</h3><ul><li>Wikipedia：<a href="https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Receiver_operating_characteristic" target="_blank" rel="noopener">Receiver operating characteristic</a></li><li>孔明的博客：<a href="https://link.jianshu.com/?t=http://alexkong.net/2013/06/introduction-to-auc-and-roc/" target="_blank" rel="noopener">ROC和AUC介绍以及如何计算AUC</a></li><li>Rachel Zhang的专栏(CSDN)：<a href="https://link.jianshu.com/?t=http://blog.csdn.net/abcjennifer/article/details/7359370" target="_blank" rel="noopener">ROC曲线-阈值评价标准</a></li><li>博客园dzl_ML：<a href="https://link.jianshu.com/?t=http://www.cnblogs.com/dlml/p/4403482.html" target="_blank" rel="noopener">机器学习之分类器性能指标之ROC曲线、AUC值</a></li><li>知乎：<a href="https://link.jianshu.com/?t=https://www.zhihu.com/question/30643044" target="_blank" rel="noopener">精确率、召回率、F1 值、ROC、AUC 各自的优缺点是什么？</a></li></ul><p>作者：zhwhong<br>链接：<a href="https://www.jianshu.com/p/c61ae11cc5f6" target="_blank" rel="noopener">https://www.jianshu.com/p/c61ae11cc5f6</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;在分类任务中，人们总是喜欢基于错误率来衡量分类器任务的成功程度。错误率指的是在所有测试样例中错分的样例比例。实际上，这样的度量错误掩盖了样例如何被分错的事实。在机器学习中，有一个普遍适用的称为混淆矩阵(&lt;a href=&quot;https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Confusion_matrix&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;confusion matrix&lt;/a&gt;)的工具，它可以帮助人们更好地了解分类中的错误。&lt;/p&gt;
&lt;p&gt;比如有这样一个在房子周围可能发现的动物类型的预测，这个预测的三类问题的混淆矩阵如下表所示：&lt;/p&gt;
&lt;p&gt;&lt;img src=&quot;https://upload-images.jianshu.io/upload_images/145616-dcd144da21bdc9b9.png?imageMogr2/auto-orient/strip%7CimageView2/2/w/403&quot; alt=&quot;&quot;&gt;&lt;/p&gt;
&lt;p&gt;一个三类问题的混淆矩阵&lt;/p&gt;
&lt;p&gt;利用混淆矩阵可以充分理解分类中的错误了。如果混淆矩阵中的非对角线元素均为0，就会得到一个近乎完美的分类器。&lt;/p&gt;
&lt;p&gt;在接下来的讨论中，将以经典的二分类问题为例，对于多分类类比推断。&lt;/p&gt;
&lt;p&gt;二分类问题在机器学习中是一个很常见的问题，经常会用到。&lt;a href=&quot;https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Receiver_operating_characteristic&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;ROC&lt;/a&gt; (Receiver Operating Characteristic) 曲线和 &lt;a href=&quot;https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Receiver_operating_characteristic#Area_under_the_curve&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;AUC&lt;/a&gt; (Area Under the Curve) 值常被用来评价一个二值分类器 (&lt;a href=&quot;https://link.jianshu.com/?t=https://en.wikipedia.org/wiki/Binary_classification&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;binary classifier&lt;/a&gt;) 的优劣。之前做医学图像计算机辅助肺结节检测时，在评定模型预测结果时，就用到了ROC和AUC，这里简单介绍一下它们的特点，以及更为深入地，讨论如何作出ROC曲线图和计算AUC值。&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="机器学习" scheme="https://zhenfenghan.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
      <category term="ROC" scheme="https://zhenfenghan.github.io/tags/ROC/"/>
    
      <category term="AUC" scheme="https://zhenfenghan.github.io/tags/AUC/"/>
    
  </entry>
  
  <entry>
    <title>t-SNE（t-分布随机邻域嵌入）算法</title>
    <link href="https://zhenfenghan.github.io/2018/04/23/t-SNE%E7%AE%97%E6%B3%95/"/>
    <id>https://zhenfenghan.github.io/2018/04/23/t-SNE算法/</id>
    <published>2018-04-23T01:01:11.000Z</published>
    <updated>2018-04-24T02:03:09.468Z</updated>
    
    <content type="html"><![CDATA[<p><strong>t-SNE(t-distributed stochastic neighbor embedding) </strong> 是用于<strong>降维</strong>的一种机器学习算法，是由 Laurens van der Maaten 和 Geoffrey Hinton在08年提出来。此外，t-SNE 是一种非线性降维算法，非常适用于高维数据降维到2维或者3维，进行可视化。</p><p>t-SNE是由SNE(Stochastic Neighbor Embedding, SNE; Hinton and Roweis, 2002)发展而来。我们先介绍SNE的基本原理，之后再扩展到t-SNE。最后再看一下t-SNE的实现以及一些优化。</p><h3 id="目录"><a href="#目录" class="headerlink" title="目录"></a>目录</h3><ul><li><a href="file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#1sne" target="_blank" rel="noopener">1.SNE</a><ul><li><a href="file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#11基本原理" target="_blank" rel="noopener">1.1基本原理</a></li><li><a href="file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#12-sne原理推导" target="_blank" rel="noopener">1.2 SNE原理推导</a></li></ul></li><li><a href="file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#2t-sne" target="_blank" rel="noopener">2.t-SNE</a><ul><li><a href="file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#21-symmetric-sne" target="_blank" rel="noopener">2.1 Symmetric SNE</a></li><li><a href="file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#22-crowding问题" target="_blank" rel="noopener">2.2 Crowding问题</a></li><li><a href="file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#23-t-sne" target="_blank" rel="noopener">2.3 t-SNE</a></li><li><a href="file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#24-算法过程" target="_blank" rel="noopener">2.4 算法过程</a></li><li><a href="file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#25-不足" target="_blank" rel="noopener">2.5 不足</a></li></ul></li><li><a href="file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#3变种" target="_blank" rel="noopener">3.变种</a></li><li><a href="file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#4参考文档" target="_blank" rel="noopener">4.参考文档</a></li><li><a href="file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#5-代码" target="_blank" rel="noopener">5. 代码</a></li></ul><a id="more"></a><h3 id="1-SNE"><a href="#1-SNE" class="headerlink" title="1.SNE"></a>1.SNE</h3><h4 id="1-1基本原理"><a href="#1-1基本原理" class="headerlink" title="1.1基本原理"></a>1.1基本原理</h4><p>SNE是通过仿射(affinitie)变换将数据点映射到概率分布上，主要包括两个步骤：</p><ul><li>SNE构建一个高维对象之间的概率分布，使得相似的对象有更高的概率被选择，而不相似的对象有较低的概率被选择。</li><li>SNE在低维空间里在构建这些点的概率分布，使得这两个概率分布之间尽可能的相似。</li></ul><p>我们看到t-SNE模型是非监督的降维，他跟kmeans等不同，他不能通过训练得到一些东西之后再用于其它数据（比如kmeans可以通过训练得到k个点，再用于其它数据集，而t-SNE只能单独的对数据做操作，也就是说他只有fit_transform，而没有fit操作）</p><h4 id="1-2-SNE原理推导"><a href="#1-2-SNE原理推导" class="headerlink" title="1.2 SNE原理推导"></a>1.2 SNE原理推导</h4><p>SNE是先<strong>将欧几里得距离转换为条件概率来表达点与点之间的相似度</strong>。具体来说，给定一个N个高维的数据 $ x_1,…,x_N  $（注意N不是维度）, t-SNE首先是计算概率$ p_{ij} $，正比于$ x_i $ 和$ x_j $ 之间的相似度（这种概率是我们自主构建的），即：</p><p>$$ {p_ {j \mid i} = \frac{\exp(- \mid \mid x_i -x_j \mid \mid ^2 / (2 \sigma^2_i ))} {\sum_{k \neq i} \exp(- \mid \mid x_i - x_k \mid \mid ^2 / (2 \sigma^2_i))}} $$</p><p>这里的有一个参数是$\sigma_i $，对于不同的点$x_i$ 取值不一样，后续会讨论如何设置。此外设置$ p_{x \mid x}=0 $,因为我们关注的是两两之间的相似度。</p><p>那对于低维度下的$ y_i $，我们可以指定高斯分布为方差为$ \frac{1}{\sqrt{2}} $，因此它们之间的相似度如下:</p><p>$$<br>{q_ {j \mid i} = \frac{\exp(- \mid \mid x_i -x_j \mid \mid ^2)} {\sum_{k \neq i} \exp(- \mid \mid x_i - x_k \mid \mid ^2)}} $$</p><p>同样，设定$ q_{i \mid i} = 0 $.</p><p>如果降维的效果比较好，局部特征保留完整，那么 $ p_{i \mid j} = q_{i \mid j} $, 因此我们优化两个分布之间的距离–KL散度(Kullback-Leibler divergences)，那么目标函数(cost function)如下:</p><p>$$<br>C = \sum_i KL(P_i \mid \mid Q_i) = \sum_i \sum_j p_{j \mid i} \log \frac{p_{j \mid i}}{q_{j \mid i}} $$</p><p>这里的$ P_i $表示了给定点$ x_i $下，其他所有数据点的条件概率分布。需要注意的是<strong>KL散度具有不对称性</strong>，在低维映射中不同的距离对应的惩罚权重是不同的，具体来说：距离较远的两个点来表达距离较近的两个点会产生更大的cost，相反，用较近的两个点来表达较远的两个点产生的cost相对较小(注意：类似于回归容易受异常值影响，但效果相反)。即用较小的 $ q_{j \mid i}=0.2 $ 来建模较大的 $ p_{j \mid i}=0.8$ , $cost= p \log(\frac{p}{q}) =1.11$,同样用较大的$ q_{j \mid i}=0.8 $ 来建模较大的$ p_{j \mid i}=0.2 , cost=-0.277$, 因此，<strong>SNE会倾向于保留数据中的局部特征</strong>。</p><blockquote><p>思考:了解了基本思路之后，你会怎么选择$ \sigma $，固定初始化?</p></blockquote><p>下面我们开始正式的推导SNE。首先不同的点具有不同的$ \sigma_i$ ，$ P_i $的熵(entropy)会随着$\sigma_i$ 的增加而增加。SNE使用困惑度(<a href="https://en.wikipedia.org/wiki/Perplexity" target="_blank" rel="noopener">perplexity</a>)的概念，用二分搜索的方式来寻找一个最佳的$\sigma$  。其中困惑度指:</p><p>$$<br>Perp(P_i) = 2^{H(P_i)}<br>$$<br>这里的$ H(P_i)$ 是$ P_i $ 的熵，即:</p><p>$$<br>H(P_i) = -\sum_j p_{j \mid i} \log_2 p_{j \mid i}<br>$$<br>困惑度可以解释为一个点附近的有效近邻点个数。<strong>SNE对困惑度的调整比较有鲁棒性，通常选择5-50之间</strong>，给定之后，使用二分搜索的方式寻找合适的$\sigma$</p><p>那么核心问题是如何求解梯度了,目标函数等价于$\sum \sum - p log(q)$ 这个式子与softmax非常的类似，我们知道softmax的目标函数是$ \sum -y \log p $，对应的梯度是$ y - p $  (注：这里的softmax中y表示label，p表示预估值)。 同样我们可以推导SNE的目标函数中的i在j下的条件概率情况的梯度是$2(p_{i \mid j}-q_{i \mid j})(y_i-y_j) $， 同样j在i下的条件概率的梯度是$2(p_{j \mid i}-q_{j \mid i})(y_i-y_j)$ , 最后得到完整的梯度公式如下:<br>$$<br>\frac{\delta C}{\delta y_i} = 2 \sum_j (p_{j \mid i} - q_{j \mid i} + p_{i \mid j} - q_{i \mid j})(y_i - y_j)<br>$$<br>在初始化中，可以用较小的$\sigma$ 下的高斯分布来进行初始化。为了加速优化过程和避免陷入局部最优解，梯度中需要使用一个相对较大的动量(momentum)。即参数更新中除了当前的梯度，还要引入之前的梯度累加的指数衰减项，如下:</p><p>$$<br>Y^{(t)} = Y^{(t-1)} + \eta \frac{\delta C}{\delta Y} + \alpha(t)(Y^{(t-1)} - Y^{(t-2)})<br>$$<br>这里的$ Y^{(t)} $表示迭代t次的解，$ \eta $表示学习速率,$\alpha(t) $表示迭代t次的动量。</p><p>此外，在初始优化的阶段，每次迭代中可以引入一些高斯噪声，之后像模拟退火一样逐渐减小该噪声，可以用来避免陷入局部最优解。因此，SNE在选择高斯噪声，以及学习速率，什么时候开始衰减，动量选择等等超参数上，需要跑多次优化才可以。</p><blockquote><p>思考:SNE有哪些不足？ 面对SNE的不足，你会做什么改进？  </p></blockquote><h3 id="2-t-SNE"><a href="#2-t-SNE" class="headerlink" title="2.t-SNE"></a>2.t-SNE</h3><p>尽管SNE提供了很好的可视化方法，但是他很难优化，而且存在”crowding problem”(拥挤问题)。后续中，Hinton等人又提出了t-SNE的方法。与SNE不同，主要如下:</p><ul><li>使用对称版的SNE，简化梯度公式</li><li>低维空间下，使用t分布替代高斯分布表达两点之间的相似度</li></ul><p>t-SNE在低维空间下使用更重长尾分布的t分布来避免crowding问题和优化问题。在这里，首先介绍一下对称版的SNE，之后介绍crowding问题，之后再介绍t-SNE。</p><h4 id="2-1-Symmetric-SNE"><a href="#2-1-Symmetric-SNE" class="headerlink" title="2.1 Symmetric SNE"></a>2.1 Symmetric SNE</h4><p>优化$ p_{i \mid j}$ 和$ q_{i \mid j} $的KL散度的一种替换思路是，使用联合概率分布来替换条件概率分布，即P是高维空间里各个点的联合概率分布，Q是低维空间下的，目标函数为:</p><p>$$<br>C = KL(P \mid \mid Q) = \sum_i \sum_j p_{i,j} \log \frac{p_{ij}}{q_{ij}}<br>$$<br>这里的$ p_{ii}$ ,$q_{ii}$ 为0，我们将这种SNE称之为symmetric SNE(对称SNE)，因为他假设了对于任意i,$ p_{ij} = p_{ji}$  , $q_{ij} = q_{ji} $，因此概率分布可以改写为:</p><p>$$<br>p_{ij} = \frac{\exp(- \mid \mid x_i - x_j \mid \mid ^2 / 2\sigma^2)}{\sum_{k \neq l} \exp(- \mid \mid x_k-x_l \mid \mid ^2 / 2\sigma^2)} \ \ \ \ q_{ij} = \frac{\exp(- \mid \mid y_i - y_j \mid \mid ^2)}{\sum_{k \neq l} \exp(- \mid \mid y_k-y_l \mid \mid ^2)}<br>$$<br>这种表达方式，使得整体简洁了很多。但是会引入<strong>异常值</strong>的问题。比如$ x_i $ 是异常值，那么$ \mid \mid x_i - x_j \mid \mid ^2 $会很大，对应的所有的j,$p_{ij} $都会很小(之前是仅在$ x_i $下很小)，导致低维映射下的$ y_i$ 对cost影响很小。</p><blockquote><p>思考: 对于异常值，你会做什么改进 ？$ p_i$ 表示什么 ？</p></blockquote><p>为了解决这个问题，我们将联合概率分布定义修正为: $ p_{ij} = \frac{p_{i \mid j} + p_{j \mid i}}{2}$ , 这保证了$\sum_j p_{ij} \gt \frac{1}{2n} $, 使得每个点对于cost都会有一定的贡献。对称SNE的最大优点是梯度计算变得简单了，如下:</p><p>$$<br>\frac{\delta C}{\delta y_i} = 4 \sum_j (p_{ij} - q_{ij})(y_i - y_j)<br>$$<br>实验中，发现对称SNE能够产生和SNE一样好的结果，有时甚至略好一点。</p><h4 id="2-2-Crowding问题"><a href="#2-2-Crowding问题" class="headerlink" title="2.2 Crowding问题"></a>2.2 Crowding问题</h4><p>拥挤问题就是说各个簇聚集在一起，无法区分。比如有一种情况，高维度数据在降维到10维下，可以有很好的表达，但是降维到两维后无法得到可信映射，比如降维如10维中有11个点之间两两等距离的，在二维下就无法得到可信的映射结果(最多3个点)。 进一步的说明，假设一个以数据点$x_i$ 为中心，半径为r的m维球(三维空间就是球)，其体积是按$ r^m $增长的，假设数据点是在m维球中均匀分布的，我们来看看其他数据点与$x_i$ 的距离随维度增大而产生的变化。</p><p><img src="http://p6ux47i4n.bkt.clouddn.com/sne_crowding.png" alt="sne_crowding.png"></p><p>从上图可以看到，随着维度的增大，大部分数据点都聚集在m维球的表面附近，与点xixixi”&gt; x_i 的距离分布极不均衡。如果直接将这种距离关系保留到低维，就会出现拥挤问题。</p><blockquote><p>怎么解决crowding问题呢？</p></blockquote><p><em>Cook et al.(2007)</em> 提出一种 slight repulsion 的方式，在基线概率分布(uniform background)中引入一个较小的混合因子$\rho$ ,这样$q_{ij}$ 就永远不会小于$ \frac{2 \rho}{n(n-1)} $(因为一共了n(n-1)个pairs)，这样在高维空间中比较远的两个点之间的$q_{ij}$ 总是会比$p_{ij}$ 大一点。这种称之为UNI-SNE，效果通常比标准的SNE要好。优化UNI-SNE的方法是先让$\rho $为0，使用标准的SNE优化，之后用模拟退火的方法的时候，再慢慢增加$\rho $. 直接优化UNI-SNE是不行的(即一开始$\rho$ 不为0)，因为距离较远的两个点基本是一样的$q_{ij} $(等于基线分布), 即使$p_{ij} $很大，一些距离变化很难在$ q_{ij}$ 中产生作用。也就是说优化中刚开始距离较远的两个聚类点，后续就无法再把他们拉近了。</p><h4 id="2-3-t-SNE"><a href="#2-3-t-SNE" class="headerlink" title="2.3 t-SNE"></a>2.3 t-SNE</h4><p>对称SNE实际上在高维度下 另外一种减轻”拥挤问题”的方法：在高维空间下，在高维空间下我们使用高斯分布将距离转换为概率分布，在低维空间下，我们使用更加偏重长尾分布的方式来将距离转换为概率分布，使得高维度下中低等的距离在映射后能够有一个较大的距离。</p><p><img src="http://p6ux47i4n.bkt.clouddn.com/norm_t_dict.png" alt="norm_t_dict.png"></p><p>我们对比一下高斯分布和t分布(如上图,code见probability/distribution.md), t分布受异常值影响更小，拟合结果更为合理，较好的捕获了数据的整体特征。</p><p>使用了t分布之后的q变化，如下:</p><p>$$<br>q_{ij} = \frac{(1 + \mid \mid y_i -y_j \mid \mid ^2)^{-1}}{\sum_{k \neq l} (1 + \mid \mid y_i -y_j \mid \mid ^2)^{-1}}<br>$$<br>此外，t分布是无限多个高斯分布的叠加，计算上不是指数的，会方便很多。优化的梯度如下:</p><p>$$<br>\frac{\delta C}{\delta y_i} = 4 \sum_j(p_{ij}-q_{ij})(y_i-y_j)(1+ \mid \mid y_i-y_j \mid \mid ^2)^{-1}<br>$$<br><img src="http://p6ux47i4n.bkt.clouddn.com/sne_norm_t_dist_cost.png" alt="ne_norm_t_dist_cost.png"></p><p>t-sne的有效性，也可以从上图中看到：横轴表示距离，纵轴表示相似度, 可以看到，对于较大相似度的点，t分布在低维空间中的距离需要稍小一点；而对于低相似度的点，t分布在低维空间中的距离需要更远。这恰好满足了我们的需求，即同一簇内的点(距离较近)聚合的更紧密，不同簇之间的点(距离较远)更加疏远。</p><p>总结一下，t-SNE的梯度更新有两大优势：</p><ul><li>对于不相似的点，用一个较小的距离会产生较大的梯度来让这些点排斥开来。</li><li>这种排斥又不会无限大(梯度中分母)，避免不相似的点距离太远。</li></ul><h4 id="2-4-算法过程"><a href="#2-4-算法过程" class="headerlink" title="2.4 算法过程"></a>2.4 算法过程</h4><p>算法详细过程如下：</p><ul><li>Data: $X = {x_1, … , x_n}$</li><li>计算cost function的参数：困惑度Perp</li><li>优化参数: 设置迭代次数T， 学习速率$\eta$ , 动量$\alpha(t)$</li><li>目标结果是低维数据表示 $ Y^T = {y_1, … , y_n}$</li><li>开始优化<ul><li>计算在给定Perp下的条件概率$ p_{j \mid i}$ (参见上面公式)</li><li>令 $ p_{ij} = \frac{p_{j \mid i} + p_{i \mid j}}{2n}$</li><li>用$N(0, 10^{-4}I) $随机初始化 Y</li><li>迭代，从 t = 1 到 T， 做如下操作:<ul><li>计算低维度下的$ q_{ij} $(参见上面的公式)</li><li>计算梯度（参见上面的公式）</li><li>更新 $ Y^{t} = Y^{t-1} + \eta \frac{dC}{dY} + \alpha(t)(Y^{t-1} - Y^{t-2})$</li></ul></li><li>结束</li></ul></li><li>结束</li></ul><p>优化过程中可以尝试的两个trick:</p><ul><li>提前压缩(early compression):开始初始化的时候，各个点要离得近一点。这样小的距离，方便各个聚类中心的移动。可以通过引入L2正则项(距离的平方和)来实现。</li><li>提前夸大(early exaggeration)：在开始优化阶段，$ p_{ij} $乘以一个大于1的数进行扩大，来避免因为$q_{ij} $太小导致优化太慢的问题。比如前50次迭代，$p_{ij} $乘以4</li></ul><p>优化的过程动态图如下：</p><p><img src="http://p6ux47i4n.bkt.clouddn.com/t-sne_optimise.gif" alt="t-sne_optimise.gif"></p><h4 id="2-5-不足"><a href="#2-5-不足" class="headerlink" title="2.5 不足"></a>2.5 不足</h4><p>主要不足有四个:</p><ul><li>主要用于可视化，很难用于其他目的。比如测试集合降维，因为他没有显式的预估部分，不能在测试集合直接降维；比如降维到10维，因为t分布偏重长尾，1个自由度的t分布很难保存好局部特征，可能需要设置成更高的自由度。</li><li>t-SNE倾向于保存局部特征，对于本征维数(intrinsic dimensionality)本身就很高的数据集，是不可能完整的映射到2-3维的空间</li><li>t-SNE没有唯一最优解，且没有预估部分。如果想要做预估，可以考虑降维之后，再构建一个回归方程之类的模型去做。但是要注意，t-sne中距离本身是没有意义，都是概率分布问题。</li><li>训练太慢。有很多基于树的算法在t-sne上做一些改进</li></ul><h3 id="3-变种"><a href="#3-变种" class="headerlink" title="3.变种"></a>3.变种</h3><p>后续有机会补充。</p><ul><li><strong>multiple maps of t-SNE</strong></li><li><strong>parametric t-SNE</strong></li><li><strong>Visualizing Large-scale and High-dimensional Data</strong></li></ul><h3 id="4-参考文档"><a href="#4-参考文档" class="headerlink" title="4.参考文档"></a>4.参考文档</h3><ul><li><em>Maaten, L., &amp; Hinton, G. (2008). Visualizing data using t-SNE. Journal of Machine Learning Research.</em></li></ul><h3 id="5-代码"><a href="#5-代码" class="headerlink" title="5. 代码"></a>5. 代码</h3><p><strong>文中的插图绘制:</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br></pre></td><td class="code"><pre><span class="line">import numpy as np</span><br><span class="line">from numpy.linalg import norm</span><br><span class="line">from matplotlib import pyplot as plt</span><br><span class="line">plt.style.use(<span class="string">'ggplot'</span>)</span><br><span class="line"></span><br><span class="line">def sne_crowding():</span><br><span class="line">    npoints = 1000 <span class="comment"># 抽取1000个m维球内均匀分布的点</span></span><br><span class="line">    plt.figure(figsize=(20, 5))</span><br><span class="line">    <span class="keyword">for</span> i, m <span class="keyword">in</span> enumerate((2, 3, 5, 8)):</span><br><span class="line">        <span class="comment"># 这里模拟m维球中的均匀分布用到了拒绝采样，</span></span><br><span class="line">        <span class="comment"># 即先生成m维立方中的均匀分布，再剔除m维球外部的点</span></span><br><span class="line">        accepts = []</span><br><span class="line">        <span class="keyword">while</span> len(accepts) &lt; 1000:</span><br><span class="line">            points = np.random.rand(500, m)</span><br><span class="line">            accepts.extend([d <span class="keyword">for</span> d <span class="keyword">in</span> norm(points, axis=1)</span><br><span class="line">                            <span class="keyword">if</span> d &lt;= 1.0]) <span class="comment"># 拒绝采样</span></span><br><span class="line">        accepts = accepts[:npoints]</span><br><span class="line">        ax = plt.subplot(1, 4, i+1)</span><br><span class="line">        <span class="keyword">if</span> i == 0:</span><br><span class="line">            ax.set_ylabel(<span class="string">'count'</span>)</span><br><span class="line">        <span class="keyword">if</span> i == 2:</span><br><span class="line"></span><br><span class="line">            ax.set_xlabel(<span class="string">'distance'</span>)</span><br><span class="line">        ax.hist(accepts, bins=np.linspace(0., 1., 50))</span><br><span class="line">        ax.set_title(<span class="string">'m=%s'</span> %m)</span><br><span class="line">    plt.savefig(<span class="string">"./images/sne_crowding.png"</span>)</span><br><span class="line"></span><br><span class="line">    x = np.linspace(0, 4, 100)</span><br><span class="line">    ta = 1 / (1 + np.square(x))</span><br><span class="line">    tb = np.sum(ta) - 1</span><br><span class="line">    qa = np.exp(-np.square(x))</span><br><span class="line">    qb = np.sum(qa) - 1</span><br><span class="line"></span><br><span class="line">def sne_norm_t_dist_cost():</span><br><span class="line">    plt.figure(figsize=(8, 5))</span><br><span class="line">    plt.plot(qa/qb, c=<span class="string">"b"</span>, label=<span class="string">"normal-dist"</span>)</span><br><span class="line">    plt.plot(ta/tb, c=<span class="string">"g"</span>, label=<span class="string">"t-dist"</span>)</span><br><span class="line">    plt.plot((0, 20), (0.025, 0.025), <span class="string">'r--'</span>)</span><br><span class="line">    plt.text(10, 0.022, r<span class="string">'$q_&#123;ij&#125;$'</span>)</span><br><span class="line">    plt.text(20, 0.026, r<span class="string">'$p_&#123;ij&#125;$'</span>)</span><br><span class="line"></span><br><span class="line">    plt.plot((0, 55), (0.005, 0.005), <span class="string">'r--'</span>)</span><br><span class="line">    plt.text(36, 0.003, r<span class="string">'$q_&#123;ij&#125;$'</span>)</span><br><span class="line">    plt.text(55, 0.007, r<span class="string">'$p_&#123;ij&#125;$'</span>)</span><br><span class="line"></span><br><span class="line">    plt.title(<span class="string">"probability of distance"</span>)</span><br><span class="line">    plt.xlabel(<span class="string">"distance"</span>)</span><br><span class="line">    plt.ylabel(<span class="string">"probability"</span>)</span><br><span class="line">    plt.legend()</span><br><span class="line">    plt.savefig(<span class="string">"./images/sne_norm_t_dist_cost.png"</span>)</span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">'__main__'</span>:</span><br><span class="line">    sne_crowding()</span><br><span class="line">    sne_norm_t_dist_cost()</span><br></pre></td></tr></table></figure></p><p><strong>t-sne的完整代码实现:</strong><br><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br><span class="line">2</span><br><span class="line">3</span><br><span class="line">4</span><br><span class="line">5</span><br><span class="line">6</span><br><span class="line">7</span><br><span class="line">8</span><br><span class="line">9</span><br><span class="line">10</span><br><span class="line">11</span><br><span class="line">12</span><br><span class="line">13</span><br><span class="line">14</span><br><span class="line">15</span><br><span class="line">16</span><br><span class="line">17</span><br><span class="line">18</span><br><span class="line">19</span><br><span class="line">20</span><br><span class="line">21</span><br><span class="line">22</span><br><span class="line">23</span><br><span class="line">24</span><br><span class="line">25</span><br><span class="line">26</span><br><span class="line">27</span><br><span class="line">28</span><br><span class="line">29</span><br><span class="line">30</span><br><span class="line">31</span><br><span class="line">32</span><br><span class="line">33</span><br><span class="line">34</span><br><span class="line">35</span><br><span class="line">36</span><br><span class="line">37</span><br><span class="line">38</span><br><span class="line">39</span><br><span class="line">40</span><br><span class="line">41</span><br><span class="line">42</span><br><span class="line">43</span><br><span class="line">44</span><br><span class="line">45</span><br><span class="line">46</span><br><span class="line">47</span><br><span class="line">48</span><br><span class="line">49</span><br><span class="line">50</span><br><span class="line">51</span><br><span class="line">52</span><br><span class="line">53</span><br><span class="line">54</span><br><span class="line">55</span><br><span class="line">56</span><br><span class="line">57</span><br><span class="line">58</span><br><span class="line">59</span><br><span class="line">60</span><br><span class="line">61</span><br><span class="line">62</span><br><span class="line">63</span><br><span class="line">64</span><br><span class="line">65</span><br><span class="line">66</span><br><span class="line">67</span><br><span class="line">68</span><br><span class="line">69</span><br><span class="line">70</span><br><span class="line">71</span><br><span class="line">72</span><br><span class="line">73</span><br><span class="line">74</span><br><span class="line">75</span><br><span class="line">76</span><br><span class="line">77</span><br><span class="line">78</span><br><span class="line">79</span><br><span class="line">80</span><br><span class="line">81</span><br><span class="line">82</span><br><span class="line">83</span><br><span class="line">84</span><br><span class="line">85</span><br><span class="line">86</span><br><span class="line">87</span><br><span class="line">88</span><br><span class="line">89</span><br><span class="line">90</span><br><span class="line">91</span><br><span class="line">92</span><br><span class="line">93</span><br><span class="line">94</span><br><span class="line">95</span><br><span class="line">96</span><br><span class="line">97</span><br><span class="line">98</span><br><span class="line">99</span><br><span class="line">100</span><br><span class="line">101</span><br><span class="line">102</span><br><span class="line">103</span><br><span class="line">104</span><br><span class="line">105</span><br><span class="line">106</span><br><span class="line">107</span><br><span class="line">108</span><br><span class="line">109</span><br><span class="line">110</span><br><span class="line">111</span><br><span class="line">112</span><br><span class="line">113</span><br><span class="line">114</span><br><span class="line">115</span><br><span class="line">116</span><br><span class="line">117</span><br><span class="line">118</span><br><span class="line">119</span><br><span class="line">120</span><br><span class="line">121</span><br><span class="line">122</span><br><span class="line">123</span><br><span class="line">124</span><br><span class="line">125</span><br><span class="line">126</span><br><span class="line">127</span><br><span class="line">128</span><br><span class="line">129</span><br><span class="line">130</span><br><span class="line">131</span><br><span class="line">132</span><br><span class="line">133</span><br><span class="line">134</span><br><span class="line">135</span><br><span class="line">136</span><br><span class="line">137</span><br><span class="line">138</span><br><span class="line">139</span><br><span class="line">140</span><br><span class="line">141</span><br><span class="line">142</span><br><span class="line">143</span><br><span class="line">144</span><br><span class="line">145</span><br><span class="line">146</span><br><span class="line">147</span><br><span class="line">148</span><br><span class="line">149</span><br><span class="line">150</span><br><span class="line">151</span><br><span class="line">152</span><br><span class="line">153</span><br><span class="line">154</span><br><span class="line">155</span><br><span class="line">156</span><br><span class="line">157</span><br><span class="line">158</span><br><span class="line">159</span><br><span class="line">160</span><br><span class="line">161</span><br><span class="line">162</span><br><span class="line">163</span><br><span class="line">164</span><br><span class="line">165</span><br><span class="line">166</span><br><span class="line">167</span><br><span class="line">168</span><br><span class="line">169</span><br><span class="line">170</span><br></pre></td><td class="code"><pre><span class="line"><span class="string">''</span><span class="string">'</span></span><br><span class="line"><span class="string">代码参考了作者Laurens van der Maaten的开放出的t-sne代码, 并没有用类进行实现,主要是优化了计算的实现</span></span><br><span class="line"><span class="string">'</span><span class="string">''</span></span><br><span class="line">import numpy as np</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def cal_pairwise_dist(x):</span><br><span class="line">    <span class="string">''</span><span class="string">'计算pairwise 距离, x是matrix</span></span><br><span class="line"><span class="string">    (a-b)^2 = a^w + b^2 - 2*a*b</span></span><br><span class="line"><span class="string">    '</span><span class="string">''</span></span><br><span class="line">    sum_x = np.sum(np.square(x), 1)</span><br><span class="line">    dist = np.add(np.add(-2 * np.dot(x, x.T), sum_x).T, sum_x)</span><br><span class="line">    <span class="built_in">return</span> dist</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def cal_perplexity(dist, idx=0, beta=1.0):</span><br><span class="line">    <span class="string">''</span><span class="string">'计算perplexity, D是距离向量，</span></span><br><span class="line"><span class="string">    idx指dist中自己与自己距离的位置，beta是高斯分布参数</span></span><br><span class="line"><span class="string">    这里的perp仅计算了熵，方便计算</span></span><br><span class="line"><span class="string">    '</span><span class="string">''</span></span><br><span class="line">    prob = np.exp(-dist * beta)</span><br><span class="line">    <span class="comment"># 设置自身prob为0</span></span><br><span class="line">    prob[idx] = 0</span><br><span class="line">    sum_prob = np.sum(prob)</span><br><span class="line">    perp = np.log(sum_prob) + beta * np.sum(dist * prob) / sum_prob</span><br><span class="line">    prob /= sum_prob</span><br><span class="line">    <span class="built_in">return</span> perp, prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def seach_prob(x, tol=1e-5, perplexity=30.0):</span><br><span class="line">    <span class="string">''</span><span class="string">'二分搜索寻找beta,并计算pairwise的prob</span></span><br><span class="line"><span class="string">    '</span><span class="string">''</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化参数</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"Computing pairwise distances..."</span>)</span><br><span class="line">    (n, d) = x.shape</span><br><span class="line">    dist = cal_pairwise_dist(x)</span><br><span class="line">    pair_prob = np.zeros((n, n))</span><br><span class="line">    beta = np.ones((n, 1))</span><br><span class="line">    <span class="comment"># 取log，方便后续计算</span></span><br><span class="line">    base_perp = np.log(perplexity)</span><br><span class="line"></span><br><span class="line">    <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">        <span class="keyword">if</span> i % 500 == 0:</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">"Computing pair_prob for point %s of %s ..."</span> %(i,n))</span><br><span class="line"></span><br><span class="line">        betamin = -np.inf</span><br><span class="line">        betamax = np.inf</span><br><span class="line">        perp, this_prob = cal_perplexity(dist[i], i, beta[i])</span><br><span class="line"></span><br><span class="line">        <span class="comment"># 二分搜索,寻找最佳sigma下的prob</span></span><br><span class="line">        perp_diff = perp - base_perp</span><br><span class="line">        tries = 0</span><br><span class="line">        <span class="keyword">while</span> np.abs(perp_diff) &gt; tol and tries &lt; 50:</span><br><span class="line">            <span class="keyword">if</span> perp_diff &gt; 0:</span><br><span class="line">                betamin = beta[i].copy()</span><br><span class="line">                <span class="keyword">if</span> betamax == np.inf or betamax == -np.inf:</span><br><span class="line">                    beta[i] = beta[i] * 2</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    beta[i] = (beta[i] + betamax) / 2</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                betamax = beta[i].copy()</span><br><span class="line">                <span class="keyword">if</span> betamin == np.inf or betamin == -np.inf:</span><br><span class="line">                    beta[i] = beta[i] / 2</span><br><span class="line">                <span class="keyword">else</span>:</span><br><span class="line">                    beta[i] = (beta[i] + betamin) / 2</span><br><span class="line"></span><br><span class="line">            <span class="comment"># 更新perb,prob值</span></span><br><span class="line">            perp, this_prob = cal_perplexity(dist[i], i, beta[i])</span><br><span class="line">            perp_diff = perp - base_perp</span><br><span class="line">            tries = tries + 1</span><br><span class="line">        <span class="comment"># 记录prob值</span></span><br><span class="line">        pair_prob[i,] = this_prob</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"Mean value of sigma: "</span>, np.mean(np.sqrt(1 / beta)))</span><br><span class="line">    <span class="built_in">return</span> pair_prob</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def pca(x, no_dims = 50):</span><br><span class="line">    <span class="string">''</span><span class="string">' PCA算法</span></span><br><span class="line"><span class="string">    使用PCA先进行预降维</span></span><br><span class="line"><span class="string">    '</span><span class="string">''</span></span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"Preprocessing the data using PCA..."</span>)</span><br><span class="line">    (n, d) = x.shape</span><br><span class="line">    x = x - np.tile(np.mean(x, 0), (n, 1))</span><br><span class="line">    l, M = np.linalg.eig(np.dot(x.T, x))</span><br><span class="line">    y = np.dot(x, M[:,0:no_dims])</span><br><span class="line">    <span class="built_in">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line">def tsne(x, no_dims=2, initial_dims=50, perplexity=30.0, max_iter=1000):</span><br><span class="line">    <span class="string">""</span><span class="string">"Runs t-SNE on the dataset in the NxD array x</span></span><br><span class="line"><span class="string">    to reduce its dimensionality to no_dims dimensions.</span></span><br><span class="line"><span class="string">    The syntaxis of the function is Y = tsne.tsne(x, no_dims, perplexity),</span></span><br><span class="line"><span class="string">    where x is an NxD NumPy array.</span></span><br><span class="line"><span class="string">    "</span><span class="string">""</span></span><br><span class="line"></span><br><span class="line">    <span class="comment"># Check inputs</span></span><br><span class="line">    <span class="keyword">if</span> isinstance(no_dims, <span class="built_in">float</span>):</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"Error: array x should have type float."</span>)</span><br><span class="line">        <span class="built_in">return</span> -1</span><br><span class="line">    <span class="keyword">if</span> round(no_dims) != no_dims:</span><br><span class="line">        <span class="built_in">print</span>(<span class="string">"Error: number of dimensions should be an integer."</span>)</span><br><span class="line">        <span class="built_in">return</span> -1</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 初始化参数和变量</span></span><br><span class="line">    x = pca(x, initial_dims).real</span><br><span class="line">    (n, d) = x.shape</span><br><span class="line">    initial_momentum = 0.5</span><br><span class="line">    final_momentum = 0.8</span><br><span class="line">    eta = 500</span><br><span class="line">    min_gain = 0.01</span><br><span class="line">    y = np.random.randn(n, no_dims)</span><br><span class="line">    dy = np.zeros((n, no_dims))</span><br><span class="line">    iy = np.zeros((n, no_dims))</span><br><span class="line">    gains = np.ones((n, no_dims))</span><br><span class="line"></span><br><span class="line">    <span class="comment"># 对称化</span></span><br><span class="line">    P = seach_prob(x, 1e-5, perplexity)</span><br><span class="line">    P = P + np.transpose(P)</span><br><span class="line">    P = P / np.sum(P)</span><br><span class="line">    <span class="comment"># early exaggeration</span></span><br><span class="line">    P = P * 4</span><br><span class="line">    P = np.maximum(P, 1e-12)</span><br><span class="line"></span><br><span class="line">    <span class="comment"># Run iterations</span></span><br><span class="line">    <span class="keyword">for</span> iter <span class="keyword">in</span> range(max_iter):</span><br><span class="line">        <span class="comment"># Compute pairwise affinities</span></span><br><span class="line">        sum_y = np.sum(np.square(y), 1)</span><br><span class="line">        num = 1 / (1 + np.add(np.add(-2 * np.dot(y, y.T), sum_y).T, sum_y))</span><br><span class="line">        num[range(n), range(n)] = 0</span><br><span class="line">        Q = num / np.sum(num)</span><br><span class="line">        Q = np.maximum(Q, 1e-12)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Compute gradient</span></span><br><span class="line">        PQ = P - Q</span><br><span class="line">        <span class="keyword">for</span> i <span class="keyword">in</span> range(n):</span><br><span class="line">            dy[i,:] = np.sum(np.tile(PQ[:,i] * num[:,i], (no_dims, 1)).T * (y[i,:] - y), 0)</span><br><span class="line"></span><br><span class="line">        <span class="comment"># Perform the update</span></span><br><span class="line">        <span class="keyword">if</span> iter &lt; 20:</span><br><span class="line">            momentum = initial_momentum</span><br><span class="line">        <span class="keyword">else</span>:</span><br><span class="line">            momentum = final_momentum</span><br><span class="line">        gains = (gains + 0.2) * ((dy &gt; 0) != (iy &gt; 0)) + (gains * 0.8) * ((dy &gt; 0) == (iy &gt; 0))</span><br><span class="line">        gains[gains &lt; min_gain] = min_gain</span><br><span class="line">        iy = momentum * iy - eta * (gains * dy)</span><br><span class="line">        y = y + iy</span><br><span class="line">        y = y - np.tile(np.mean(y, 0), (n, 1))</span><br><span class="line">        <span class="comment"># Compute current value of cost function</span></span><br><span class="line">        <span class="keyword">if</span> (iter + 1) % 100 == 0:</span><br><span class="line">            <span class="keyword">if</span> iter &gt; 100:</span><br><span class="line">                C = np.sum(P * np.log(P / Q))</span><br><span class="line">            <span class="keyword">else</span>:</span><br><span class="line">                C = np.sum( P/4 * np.log( P/4 / Q))</span><br><span class="line">            <span class="built_in">print</span>(<span class="string">"Iteration "</span>, (iter + 1), <span class="string">": error is "</span>, C)</span><br><span class="line">        <span class="comment"># Stop lying about P-values</span></span><br><span class="line">        <span class="keyword">if</span> iter == 100:</span><br><span class="line">            P = P / 4</span><br><span class="line">    <span class="built_in">print</span>(<span class="string">"finished training!"</span>)</span><br><span class="line">    <span class="built_in">return</span> y</span><br><span class="line"></span><br><span class="line"></span><br><span class="line"><span class="keyword">if</span> __name__ == <span class="string">"__main__"</span>:</span><br><span class="line">    <span class="comment"># Run Y = tsne.tsne(X, no_dims, perplexity) to perform t-SNE on your dataset.</span></span><br><span class="line">    X = np.loadtxt(<span class="string">"mnist2500_X.txt"</span>)</span><br><span class="line">    labels = np.loadtxt(<span class="string">"mnist2500_labels.txt"</span>)</span><br><span class="line">    Y = tsne(X, 2, 50, 20.0)</span><br><span class="line">    from matplotlib import pyplot as plt</span><br><span class="line">    plt.scatter(Y[:,0], Y[:,1], 20, labels)</span><br><span class="line">    plt.show()</span><br></pre></td></tr></table></figure></p><p align="right"><em>转自 ：<a href="http://www.datakit.cn/blog/2017/02/05/t_sne_full.html" target="_blank" rel="noopener">http://www.datakit.cn/blog/2017/02/05/t_sne_full.html</a></em></p>  ]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;t-SNE(t-distributed stochastic neighbor embedding) &lt;/strong&gt; 是用于&lt;strong&gt;降维&lt;/strong&gt;的一种机器学习算法，是由 Laurens van der Maaten 和 Geoffrey Hinton在08年提出来。此外，t-SNE 是一种非线性降维算法，非常适用于高维数据降维到2维或者3维，进行可视化。&lt;/p&gt;
&lt;p&gt;t-SNE是由SNE(Stochastic Neighbor Embedding, SNE; Hinton and Roweis, 2002)发展而来。我们先介绍SNE的基本原理，之后再扩展到t-SNE。最后再看一下t-SNE的实现以及一些优化。&lt;/p&gt;
&lt;h3 id=&quot;目录&quot;&gt;&lt;a href=&quot;#目录&quot; class=&quot;headerlink&quot; title=&quot;目录&quot;&gt;&lt;/a&gt;目录&lt;/h3&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#1sne&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;1.SNE&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#11基本原理&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;1.1基本原理&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#12-sne原理推导&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;1.2 SNE原理推导&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#2t-sne&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;2.t-SNE&lt;/a&gt;&lt;ul&gt;
&lt;li&gt;&lt;a href=&quot;file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#21-symmetric-sne&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;2.1 Symmetric SNE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#22-crowding问题&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;2.2 Crowding问题&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#23-t-sne&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;2.3 t-SNE&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#24-算法过程&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;2.4 算法过程&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#25-不足&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;2.5 不足&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#3变种&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;3.变种&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#4参考文档&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;4.参考文档&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href=&quot;file:///D:/Program%20Files/HexoEditor/resources/app.asar/views/main/index.html#5-代码&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;5. 代码&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="t-SNE" scheme="https://zhenfenghan.github.io/tags/t-SNE/"/>
    
      <category term="降维" scheme="https://zhenfenghan.github.io/tags/%E9%99%8D%E7%BB%B4/"/>
    
      <category term="机器学习" scheme="https://zhenfenghan.github.io/tags/%E6%9C%BA%E5%99%A8%E5%AD%A6%E4%B9%A0/"/>
    
  </entry>
  
  <entry>
    <title>PMCAFF 2018 第二期产品学徒</title>
    <link href="https://zhenfenghan.github.io/2018/04/19/pmcaff%E6%8A%A5%E5%91%8A/"/>
    <id>https://zhenfenghan.github.io/2018/04/19/pmcaff报告/</id>
    <published>2018-04-19T01:01:11.000Z</published>
    <updated>2018-04-23T11:47:45.366Z</updated>
    
    <content type="html"><![CDATA[<p><strong>PMCAFF 2018 第二期产品学徒</strong>  </p><h3 id="网易公开课产品体验报告"><a href="#网易公开课产品体验报告" class="headerlink" title="网易公开课产品体验报告"></a>网易公开课产品体验报告</h3><p><em>Slogan：让分享知识成为习惯</em></p><p>报告链接：<a href="https://www.pmcaff.com/discuss/answer/1179912791644224" target="_blank" rel="noopener">https://www.pmcaff.com/discuss/answer/1179912791644224</a>  </p><h3 id="超级课程表产品体验报告"><a href="#超级课程表产品体验报告" class="headerlink" title="超级课程表产品体验报告"></a>超级课程表产品体验报告</h3><p><em>Slogan：大学生必备App</em>    </p><p>报告链接：<a href="https://www.pmcaff.com/discuss/answer/1182835810293824" target="_blank" rel="noopener">https://www.pmcaff.com/discuss/answer/1182835810293824</a>  </p><h3 id="网易云课堂产品体验报告"><a href="#网易云课堂产品体验报告" class="headerlink" title="网易云课堂产品体验报告"></a>网易云课堂产品体验报告</h3><p><em>Slogan：知识与技能学习平台</em><br><a id="more"></a><br>报告链接：<a href="https://www.pmcaff.com/discuss/answer/1185947544815680" target="_blank" rel="noopener">https://www.pmcaff.com/discuss/answer/1185947544815680</a>  </p><h3 id="腾讯课堂产品体验报告"><a href="#腾讯课堂产品体验报告" class="headerlink" title="腾讯课堂产品体验报告"></a>腾讯课堂产品体验报告</h3><p><em>Slogan：专业的直播学习平台</em><br>报告链接：<br><a href="https://www.pmcaff.com/discuss/answer/1190143442625600" target="_blank" rel="noopener">https://www.pmcaff.com/discuss/answer/1190143442625600</a>  </p><h3 id="百词斩产品体验报告"><a href="#百词斩产品体验报告" class="headerlink" title="百词斩产品体验报告"></a>百词斩产品体验报告</h3><p><em>Slogan：背单词、学英语必备</em>  </p><p>报告链接： <a href="https://www.pmcaff.com/discuss/answer/1192963570789440" target="_blank" rel="noopener">https://www.pmcaff.com/discuss/answer/1192963570789440</a></p><h3 id="有道云笔记产品体验报告"><a href="#有道云笔记产品体验报告" class="headerlink" title="有道云笔记产品体验报告"></a>有道云笔记产品体验报告</h3><p><em>Slogan：支持扫描、语音速记等多种记录方式</em>  </p><p>报告链接：<a href="https://www.pmcaff.com/discuss/answer/1195899178910784" target="_blank" rel="noopener">https://www.pmcaff.com/discuss/answer/1195899178910784</a></p><h3 id="腾讯翻译君产品体验报告"><a href="#腾讯翻译君产品体验报告" class="headerlink" title="腾讯翻译君产品体验报告"></a>腾讯翻译君产品体验报告</h3><p><em>Slogan：英语词典和语音翻译</em>  </p><p>报告链接：<br><a href="https://www.pmcaff.com/discuss/answer/1200308012176448" target="_blank" rel="noopener">https://www.pmcaff.com/discuss/answer/1200308012176448</a></p><h3 id="有道翻译官产品体验报告"><a href="#有道翻译官产品体验报告" class="headerlink" title="有道翻译官产品体验报告"></a>有道翻译官产品体验报告</h3><p><em>Slogan：107种语言的随身翻译软件</em>  </p><p>报告链接：<a href="https://www.pmcaff.com/discuss/answer/1203118397412416" target="_blank" rel="noopener">https://www.pmcaff.com/discuss/answer/1203118397412416</a></p><h3 id="轻芒阅读产品体验报告"><a href="#轻芒阅读产品体验报告" class="headerlink" title="轻芒阅读产品体验报告"></a>轻芒阅读产品体验报告</h3><p><em>Slogan:在一个应用里刷你关心应用的内容</em>  </p><p>报告链接：<a href="https://www.pmcaff.com/discuss/answer/1206089174391872" target="_blank" rel="noopener">https://www.pmcaff.com/discuss/answer/1206089174391872</a></p><h3 id="喜马拉雅FM产品体验报告"><a href="#喜马拉雅FM产品体验报告" class="headerlink" title="喜马拉雅FM产品体验报告"></a>喜马拉雅FM产品体验报告</h3><p><em>Slogan：随时随地，听我想听</em>  </p><p>报告链接：<br><a href="https://www.pmcaff.com/discuss/answer/1216180173690944" target="_blank" rel="noopener">https://www.pmcaff.com/discuss/answer/1216180173690944</a></p><div align="center"><br><img src="http://p6ux47i4n.bkt.clouddn.com/pmcaff%20%E4%BC%98%E7%A7%80%E5%AD%A6%E5%91%98.jpg/500.400" alt="chanpinxuetu.jpg">　<br></div> ]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;strong&gt;PMCAFF 2018 第二期产品学徒&lt;/strong&gt;  &lt;/p&gt;
&lt;h3 id=&quot;网易公开课产品体验报告&quot;&gt;&lt;a href=&quot;#网易公开课产品体验报告&quot; class=&quot;headerlink&quot; title=&quot;网易公开课产品体验报告&quot;&gt;&lt;/a&gt;网易公开课产品体验报告&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Slogan：让分享知识成为习惯&lt;/em&gt;&lt;/p&gt;
&lt;p&gt;报告链接：&lt;a href=&quot;https://www.pmcaff.com/discuss/answer/1179912791644224&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.pmcaff.com/discuss/answer/1179912791644224&lt;/a&gt;  &lt;/p&gt;
&lt;h3 id=&quot;超级课程表产品体验报告&quot;&gt;&lt;a href=&quot;#超级课程表产品体验报告&quot; class=&quot;headerlink&quot; title=&quot;超级课程表产品体验报告&quot;&gt;&lt;/a&gt;超级课程表产品体验报告&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Slogan：大学生必备App&lt;/em&gt;    &lt;/p&gt;
&lt;p&gt;报告链接：&lt;a href=&quot;https://www.pmcaff.com/discuss/answer/1182835810293824&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;https://www.pmcaff.com/discuss/answer/1182835810293824&lt;/a&gt;  &lt;/p&gt;
&lt;h3 id=&quot;网易云课堂产品体验报告&quot;&gt;&lt;a href=&quot;#网易云课堂产品体验报告&quot; class=&quot;headerlink&quot; title=&quot;网易云课堂产品体验报告&quot;&gt;&lt;/a&gt;网易云课堂产品体验报告&lt;/h3&gt;&lt;p&gt;&lt;em&gt;Slogan：知识与技能学习平台&lt;/em&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="PMCAFF" scheme="https://zhenfenghan.github.io/tags/PMCAFF/"/>
    
      <category term="产品" scheme="https://zhenfenghan.github.io/tags/%E4%BA%A7%E5%93%81/"/>
    
  </entry>
  
  <entry>
    <title>AI黑箱：用AI解释AI？</title>
    <link href="https://zhenfenghan.github.io/2018/04/15/AI%E9%BB%91%E7%AE%B1/"/>
    <id>https://zhenfenghan.github.io/2018/04/15/AI黑箱/</id>
    <published>2018-04-15T02:01:11.000Z</published>
    <updated>2018-04-19T02:27:52.779Z</updated>
    
    <content type="html"><![CDATA[<p><em>概要：AI算法对人类生活的影响越来越大，但它们内部的运作往往是不透明的，人们对这种技术的工作方式也愈加感到担忧。</em></p><div align="center"><br><img src="http://p6ux47i4n.bkt.clouddn.com/ai.jpg" alt="ai.jpg"><br></div><br>AI算法对人类生活的影响越来越大，但它们内部的运作往往是不透明的，人们对这种技术的工作方式也愈加感到担忧。MIT科技评论曾经发表一篇题为“人工智能中的黑暗秘密”的文章，警告说：“没有人真正知道先进的机器学习算法是怎样工作的，而这恐将成为一大隐忧。”由于这种不确定性和缺乏问责制，纽约大学AI Now Institute的一份报告建议负责刑事司法、医疗保健、社会福利和教育的公共机构不应该使用AI技术。<br><a id="more"></a><br>输入的数据和答案之间的不可观察的空间通常被称为“黑箱”（black box）——名称来自飞机上强制使用的飞行记录仪“黑匣子”（实际上是橙色的，而非黑色），并且经常在空难事故后用于向调查人员提供有关飞机当时运作情况的数据。在人工智能领域，这个术语描述了AI技术如何在“暗处”运作的景象：我们提供数据、模型和架构，然后计算机给出答案，同时以一种看似不可能的方式继续学习——显然对于我们人类来说，这太难理解了。<br><div align="center"><br><img src="http://p6ux47i4n.bkt.clouddn.com/black-box-input-output.png" alt="balckbox.png"><br></div><br>### 黑箱没有什么可怕的<br><br>在医疗领域，这个问题尤其被关注。AI被用于区分哪些皮肤病变是癌变，从血液中识别早期癌症，预测心脏疾病，确定人和动物的哪些化合物可以延长寿命，等等。但是，对黑箱的这些担忧是不必要的。AI的透明程度并不亚于医生一直以来的工作方式——在许多情况下，AI甚至是一种进步，它增强了医院的能力，对病人和整个医疗系统都有积极的作用。毕竟，对于新技术来说，AI的黑箱问题并不是一个新问题：人类智能本身就是一个黑箱，而且一直都是。<br><br>让我们来看一个人类医生做诊断的例子。病人可能会问医生她是如何做出诊断的，医生可能会说出一些她用来得出结论的数据。但她真的能够解释她是如何、以及为什么得出这个结论吗,她从哪些研究中得到哪些具体数据,她从所受的教育或导师那里得到了什么影响,她从自己以及同事的共同经验中得到哪些隐性知识，以及所有这些的结合如何引导她得出那个诊断?当然，她可能会说出引领她往某个特定方向走的某些指示，但这也会有猜测的成分，有跟随直觉的成分。即使没有，我们也仍然不知道有没有什么其他因素是她自己甚至没有意识到的。<br><br>如果使用AI进行同样的诊断，我们可以从该患者的所有可用信息中获取数据，以及在不同时间和从其他无数同类患者身上匿名收集的数据，用以做出最有力的基于证据的决策。这是一种与数据直接相关的诊断，而不是基于有限数据的人类直觉，或者相对少的局部患者的诊断经验总结。<br><div align="center"><br><img src="http://p6ux47i4n.bkt.clouddn.com/Main_Day1_Healthcare_MOV8_Patient_v06.gif" alt="aiinhealthy.gif"><br></div><br>但是，我们每天都必须在很多我们并不完全了解的领域做决策——并且通常都非常成功——从预测政策对经济的影响到天气预报，再到我们最初接触大部分科学的方式。我们要么认为这些决策非常简单，要么接受它们过于复杂以至我们无法解决，更不用说完全解释它们了。这就像AI的黑箱：人类的智慧能够针对一个给出的结论进行推理和论证，但无法解释我们得出一个特定结论的复杂、隐含的过程。<br><br>试想一下一对夫妻因某个明确的原因（例如，不忠）而离婚这个问题——在现实中，有许多完全看不见的、错综复杂的原因、影响和事件共同促成了这一结果。为什么这一对夫妇选择分手，而另一对类似情况的夫妇却没有?即使是处于这些关系中的人也无法完全解释这个问题。这是一个黑箱。<br><br>### AI的黑箱更多是一个特征，而不是一个bug<br><br>具有讽刺意味的是，与人类智能相比，人工智能实际上更加透明。与人类的思维不同，人工智能可以——也应该——被审问和被解释。例如检查和改进模型的能力，揭示深度神经网络中的知识差距，必须要构建的调试工具，以及通过脑机接口增强人类只能的潜在能力，等等，有许多技术可以帮助解释人工智能，而这些解释AI的方式无法用于解释人脑。在这个过程中，我们甚至可以更多地了解人类智能的运作方式。<br><br>也许批评者们担忧的真正原因不是我们无法“看到”AI的推理过程，而是当AI变得愈加强大时，人类的心智就变成了限制因素。他们担心的是，在未来，我们需要利用AI去理解AI。<br><br>在医疗领域以及其他领域，这意味着我们很快就会看到一个新类别的专业人士的出现，他们自己不必去做即时的决策，而是管理一个AI工人去做决策——就像商用飞机的驾驶员在恶劣的天气条件下使用自动驾驶仪降落一样。医生将不再“主导”初始诊断；相反，他们需要确保AI系统对患者的诊断是相关的和易于理解的，并监督AI在何时以及如何提供更多的说明和解释。未来的医生办公室很可能有多名计算机助理，包括医生方面的和病人方面的，以及来自外部的数据输入。<br><div align="center"><br><img src="http://p6ux47i4n.bkt.clouddn.com/AI-governance-lead.jpg/600.400" alt="aiinhealthy.jpg"><br></div><br>当这种情况成为现实时，显然，所谓的人工智能“黑箱”将更多是一种特征，而不是一个bug——因为它相比人类的大脑更能够理解和解释决策的过程。这并没有否定或忽视对AI进行监督的需求，只是说与其担心黑箱，我们更应该关注机会，从而更好地应对这样一个未来：AI不仅增强人类智能和人类直觉，而且甚至可以启发人之本质。<br><br>### 不要为了可解释性牺牲AI的能力<br><br>当前的AI系统可能会发生一些故障，例如使自动驾驶汽车遭遇事故，或在用于司法时对黑人判处相比白人更长的刑期。我们会知道这些，是因为AI已经在这些方面出现了错误。但是，这并不意味着我们应该坚持AI需要解释它在任何情况下如何做决策，包括欧盟的“一般数据保护条例”（GDPR）也如此要求。<br><div align="center"><br><img src="http://p6ux47i4n.bkt.clouddn.com/AIDRIVING.jpeg/600.400" alt="aiDRIVING.jpg"><br></div><br>要求可解释性听起来不错，但实现它可能需要让AI人为地变蠢。机器学习有如此强大的使用前景，缩减AI的能力可能意味着无法诊断疾病、无法发现气候变化的重要原因，等等。充分利用机器学习的能力意味着必须依赖那些现在无法向人类大脑解释的结果。<br><br>机器学习，特别是深度学习，可以将数据分析成数以千计的变量，将它们排列成非常复杂而敏感的加权关系数组，然后通过基于计算机的神经网络反复运行这些数组。要想理解这些运行的结果，例如为什么系统认为有73％的几率患上糖尿病，或者在象棋中走这步棋有84％的几率能导致最终胜利，这就需要理解这些成千上万的变量之间的关系，这些变量是通过大量的神经网络计算得出的。我们的大脑根本无法掌握这么多的信息。<br><div align="center"><br><img src="http://p6ux47i4n.bkt.clouddn.com/deep-learning-medicine-miccai.jpg/600.400" alt="aiinhealthy.jpg"><br></div> <p>可解释性是工具：我们用这些工具来达成目标。通过机器学习，可解释性能够帮助开发人员debug。可解释性也可以用来判断一个结果是否基于不应该计数的因素（例如性别，种族等，取决于具体情况）来评估责任。但是，我们可以通过其他方法来实现预期的效果，而不用约束机器学习系统的能力。</p><p>一个很有前景的工具是优化（optimization）。例如，在20世纪70年代石油危机期间，美国政府决定将限速降至55英里/时，从而优化高速公路。同样，政府也可以决定对自动驾驶汽车进行优化。</p><p>AI系统需要对针对某个目的的优化及其结果保持透明，特别是对我们希望它们支持的一些关键值保持透明。但是不一定要求算法是透明的。如果一个系统没有达到它的目标，就需要对它进行调优。如果达到了目标，可解释性就不是必要的。</p><p>通过将AI的可解释性问题视为优化问题，我们可以将争论集中在真正重要的问题上：我们想从一个系统中得到什么，我们愿意放弃什么来得到它？  </p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;&lt;em&gt;概要：AI算法对人类生活的影响越来越大，但它们内部的运作往往是不透明的，人们对这种技术的工作方式也愈加感到担忧。&lt;/em&gt;&lt;/p&gt;
&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://p6ux47i4n.bkt.clouddn.com/ai.jpg&quot; alt=&quot;ai.jpg&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;AI算法对人类生活的影响越来越大，但它们内部的运作往往是不透明的，人们对这种技术的工作方式也愈加感到担忧。MIT科技评论曾经发表一篇题为“人工智能中的黑暗秘密”的文章，警告说：“没有人真正知道先进的机器学习算法是怎样工作的，而这恐将成为一大隐忧。”由于这种不确定性和缺乏问责制，纽约大学AI Now Institute的一份报告建议负责刑事司法、医疗保健、社会福利和教育的公共机构不应该使用AI技术。&lt;br&gt;
    
    </summary>
    
    
      <category term="AI" scheme="https://zhenfenghan.github.io/tags/AI/"/>
    
      <category term="黑箱" scheme="https://zhenfenghan.github.io/tags/%E9%BB%91%E7%AE%B1/"/>
    
  </entry>
  
  <entry>
    <title>信息茧房</title>
    <link href="https://zhenfenghan.github.io/2018/04/10/%E4%BF%A1%E6%81%AF%E8%8C%A7%E6%88%BF/"/>
    <id>https://zhenfenghan.github.io/2018/04/10/信息茧房/</id>
    <published>2018-04-10T06:01:11.000Z</published>
    <updated>2018-04-10T06:29:16.192Z</updated>
    
    <content type="html"><![CDATA[<h3 id="信息流"><a href="#信息流" class="headerlink" title="信息流"></a>信息流</h3><p><div align="center"><br><img src="http://p6ux47i4n.bkt.clouddn.com/feed.jpg/600" alt="Feed.jpg"><br></div><br>信息流充斥在我们生活中的每一个角落，如同河流一样哺育着每一个人。我们阅读的每一条新闻、看的每一段视频，一切通过信息流出现在我们眼前的东西，多多少少都受到了智能推荐的驱动。<br>　<br><a id="more"></a></p><h3 id="智能推荐如何才能了解用户？"><a href="#智能推荐如何才能了解用户？" class="headerlink" title="智能推荐如何才能了解用户？"></a>智能推荐如何才能了解用户？</h3><p><div align="center"><br><img src="http://p6ux47i4n.bkt.clouddn.com/passive.jpeg" alt="passive.jpg">　　<br></div><br><strong>主动与被动间的认知鸿沟。</strong>　　<br>其实智能推荐的行为逻辑很简单，那就是把适合的内容推荐给适合的用户。但在简单的行为逻辑中的，却是智能推荐的本质：内容和用户两方面的双向深度理解。</p><p>首先在对用户的理解上，很多平台都会陷入一个误区，那就是把用户的被动反应当成了主动索求。</p><p>比如很多资讯类推荐平台<strong>冷启动</strong>时，都会让用户选择自己感兴趣的话题，这一行为就已经把用户画像圈定在了平台自己设置的范围之内。实际这种理解用户的方式略有片面，即使不断挖掘也只能察觉到用户在阅读这一个场景中的状态，无法察觉用户在阅读中的喜好、无法察觉用户当下的需求。</p><p>这也就形成了信息流最严重的污名——信息茧房，智能推荐只会根据用户的兴趣爱好推荐内容，久而久之用户就会被自己关心的事物围绕，从而失去对外界的整体认知。尤其当低俗、猎奇、软色情这些刺激眼球的信息出现时，人们难免会因为下意识的好奇进行浏览，这一典型的被动反应将相关的标签加入了用户画像中，导致相关内容大量污染用户的信息流。</p><p>其实有时候信息茧房的形成并非内容出产者和平台故意灌输带有刺激性的内容给用户，而是一些信息流产品缺少获取用户主动索取行为的途径，犹如将用户放置入一个狭小的环境中，用户对环境产生的一点点反应都会在环境中形成反复的回声。可我们无法确定环境之外用户的主动行为，从而形成了巨大的认知鸿沟。</p><h3 id="信息茧房的负面影响"><a href="#信息茧房的负面影响" class="headerlink" title="信息茧房的负面影响"></a>信息茧房的负面影响</h3><p><div align="center"><br><img src="http://p6ux47i4n.bkt.clouddn.com/jianfang.jpg" alt="Cocoon.jpg">　　<br></div><br>客观看，“信息茧房”的产生在一定程度上顺应了当前媒体去中心化、裂变化、社交化的内容生产模式，体现了媒体主动迎合用户需求的趋势。但“信息茧房”带来的负面影响也不容忽视。　　</p><p>一方面，它<strong>加剧了网络群体的极化</strong>。在网络空间，网民通过血缘、地缘、学缘、业缘等关系产生分化和类聚，进而形成“信息茧房”。他们内部之间畅聊甚欢，但也慢慢减少了与外部其他群体之间的交流。群体成员之间接触到的信息、观点和看法基本上是一样的，群体同质化趋向日益显著。在这样的“信息茧房”内，人们容易将自己的偏见当作真理，将他人的合理观点拒之于千里之外。　　<br>　　<br>另一方面，它<strong>导致社会黏性降低</strong>。在“信息茧房”里，人们对信息的选择性输入不断增强。长期沉浸在自我话语体系中，排斥异己的观点和价值观，容易产生脱离社会的倾向，对小群体外的个人和社会漠不关心，导致整个社会黏性降低，形成社会共识、增强社会凝聚力日益困难。</p>]]></content>
    
    <summary type="html">
    
      &lt;h3 id=&quot;信息流&quot;&gt;&lt;a href=&quot;#信息流&quot; class=&quot;headerlink&quot; title=&quot;信息流&quot;&gt;&lt;/a&gt;信息流&lt;/h3&gt;&lt;p&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;img src=&quot;http://p6ux47i4n.bkt.clouddn.com/feed.jpg/600&quot; alt=&quot;Feed.jpg&quot;&gt;&lt;br&gt;&lt;/div&gt;&lt;br&gt;信息流充斥在我们生活中的每一个角落，如同河流一样哺育着每一个人。我们阅读的每一条新闻、看的每一段视频，一切通过信息流出现在我们眼前的东西，多多少少都受到了智能推荐的驱动。&lt;br&gt;　&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="推荐系统" scheme="https://zhenfenghan.github.io/tags/%E6%8E%A8%E8%8D%90%E7%B3%BB%E7%BB%9F/"/>
    
  </entry>
  
  <entry>
    <title>PCA数据降维</title>
    <link href="https://zhenfenghan.github.io/2018/04/09/PCA%E6%95%B0%E6%8D%AE%E9%99%8D%E7%BB%B4/"/>
    <id>https://zhenfenghan.github.io/2018/04/09/PCA数据降维/</id>
    <published>2018-04-09T14:01:11.000Z</published>
    <updated>2018-04-10T01:17:11.628Z</updated>
    
    <content type="html"><![CDATA[<h2 id="降维的作用"><a href="#降维的作用" class="headerlink" title="降维的作用"></a><strong>降维的作用</strong></h2><ul><li>数据在低维下更容易处理、更容易使用；</li><li>相关特征，特别是重要特征更能在数据中明确的显示出来；如果只有两维或者三维的话，更便于可视化展示；</li><li>去除数据噪声</li><li>降低算法开销</li></ul><a id="more"></a><h2 id="降维通俗点的解释"><a href="#降维通俗点的解释" class="headerlink" title="降维通俗点的解释"></a><strong>降维通俗点的解释</strong></h2><p>一些高维度的数据，比如淘宝交易数据，为便于解释降维作用，我们在这假设有下单数，付款数，商品类别，售价四个维度，数据量上百万条，对于下单数和付款数，我们可以认为两者是线性相关的，即知道下单数，我们可以得到付款数，这里很明显这两个属性维度有冗余，去掉下单数，保留付款数，明显能再保证原有数据分布和信息的情况下有效简化数据，对于后面的模型学习会缩短不少时间和空间开销。这就是降维，当然并不是所有数据中都会有过于明显线性相关的属性维度，我们降维后最终的目标是各个属性维度之间线性无关。</p><h2 id="PCA降维步骤原理"><a href="#PCA降维步骤原理" class="headerlink" title="PCA降维步骤原理"></a><strong>PCA降维步骤原理</strong></h2><p>首先既然要度量那些是否存在相关的属性，我们就要用到协方差，这里不再赘述，协方差衡量的是2维属性间的相关性，对于n个维度的属性，就需要协方差矩阵，其对角线为各维度的方差。</p><p><strong>步骤：</strong></p><p> 设有m条n维数据。</p><p><strong>                      1）将原始数据按列组成n行m列矩阵X</strong></p><p><strong>                      2）将X的每一行（代表一个属性字段）进行零均值化，即减去这一行的均值</strong></p><p><strong>                      3）求出协方差矩阵</strong></p><p><strong>                      4）求出协方差矩阵的特征值及对应的特征向量r</strong></p><p><strong>                      5）将特征向量按对应特征值大小从上到下按行排列成矩阵，取前k行组成矩阵P</strong></p><p><strong>                      6）即为降维到k维后的数据</strong></p><h2 id="关于维数k的选择"><a href="#关于维数k的选择" class="headerlink" title="关于维数k的选择"></a><strong>关于维数k的选择</strong></h2><p>使用一个公式 ：   <strong><em>error = </em></strong><br><img src="http://p6ux47i4n.bkt.clouddn.com/pca_error.png" alt="PCA">，<br>表示压缩后的误差，m所有特征的个数，然后确定一个阈值x，比如0.01，选取一个K，使得error &lt; x则我们认为这个m可以接受，否则尝试其他.</p><h2 id="python中sklearn库的pca实现"><a href="#python中sklearn库的pca实现" class="headerlink" title="python中sklearn库的pca实现"></a><strong>python中sklearn库的pca实现</strong></h2><p><img src="http://p6ux47i4n.bkt.clouddn.com/pca.png" alt="pca"></p>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;降维的作用&quot;&gt;&lt;a href=&quot;#降维的作用&quot; class=&quot;headerlink&quot; title=&quot;降维的作用&quot;&gt;&lt;/a&gt;&lt;strong&gt;降维的作用&lt;/strong&gt;&lt;/h2&gt;&lt;ul&gt;
&lt;li&gt;数据在低维下更容易处理、更容易使用；&lt;/li&gt;
&lt;li&gt;相关特征，特别是重要特征更能在数据中明确的显示出来；如果只有两维或者三维的话，更便于可视化展示；&lt;/li&gt;
&lt;li&gt;去除数据噪声&lt;/li&gt;
&lt;li&gt;降低算法开销&lt;/li&gt;
&lt;/ul&gt;
    
    </summary>
    
    
      <category term="PCA" scheme="https://zhenfenghan.github.io/tags/PCA/"/>
    
      <category term="Python" scheme="https://zhenfenghan.github.io/tags/Python/"/>
    
  </entry>
  
  <entry>
    <title>梨花风起正清明</title>
    <link href="https://zhenfenghan.github.io/2018/04/05/%E6%B8%85%E6%98%8E/"/>
    <id>https://zhenfenghan.github.io/2018/04/05/清明/</id>
    <published>2018-04-05T14:01:11.000Z</published>
    <updated>2018-04-09T03:50:18.180Z</updated>
    
    <content type="html"><![CDATA[<h2 id="一朝春醒-万物清明"><a href="#一朝春醒-万物清明" class="headerlink" title="一朝春醒 万物清明"></a>一朝春醒 万物清明</h2><div align="center"><br><iframe frameborder="no" border="0" marginwidth="0" marginheight="0" width="330" height="86" src="//music.163.com/outchain/player?type=2&id=139377&auto=0&height=66"></iframe><br></div> <div align="center"><br><a href="https://imgchr.com/i/CiU5uR" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2018/04/09/CiU5uR.jpg" alt="CiU5uR.jpg"></a><br></div>   <p><strong><em>“万物生长此时，皆清洁明净。故谓之清明。”</em></strong><br>在我国，很少有一个节日，像清明这样意蕴深厚而含混：风清景明，慎终追远，这是一个悲怆的日子；放歌踏青，追逐春天，这又是一个轻盈的日子。<strong>清明是唯一一个既是节气又是节日的日子。</strong>  </p><ul><li>为测试博客，特此附上有关清明的诗词。<a id="more"></a><div align="center"><br><a href="https://imgchr.com/i/CCD3jJ" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2018/04/06/CCD3jJ.jpg" alt="CCD3jJ.jpg"></a><br></div>   <h3 id="苏堤清明即事"><a href="#苏堤清明即事" class="headerlink" title="苏堤清明即事"></a><center><strong>苏堤清明即事</strong></center></h3></li></ul><p><center>作者：吴惟信 (宋)</center></p><p><center><strong><em>梨花风起正清明，游子寻春半出城。</em></strong></center></p><p><center>日暮笙歌收拾去，万株杨柳属流莺。</center></p><hr><h3 id="破阵子"><a href="#破阵子" class="headerlink" title="破阵子"></a><center><strong>破阵子</strong></center></h3><p><center>作者：晏殊 (宋)</center></p><p><center><strong><em>燕子来时新社，梨花落后清明。</em></strong></center></p><p><center>池上碧苔三四点，叶底黄鹂一两声，日长飞絮轻。</center></p><p><center>巧笑东邻女伴，采桑径里逢迎。</center></p><p><center><strong><em>疑怪昨宵春梦好，元是今朝斗草赢，笑从双脸生。</em></strong></center></p><hr><div align="center"><br><a href="https://imgchr.com/i/CCBJFf" target="_blank" rel="noopener"><img src="https://s1.ax1x.com/2018/04/06/CCBJFf.jpg" alt="CCBJFf.jpg"></a><br></div><h3 id="临安春雨初霁"><a href="#临安春雨初霁" class="headerlink" title="临安春雨初霁"></a><center><strong>临安春雨初霁</strong></center></h3><p><center>（宋）陆游</center></p><p><center>世味年来薄似纱，谁令骑马客京华？</center></p><p><center><strong><em>小楼一夜听春雨，深巷明朝卖杏花。</em></strong></center></p><p><center>矮纸斜行闲作草，晴窗细乳戏分茶。</center></p><p><center>素衣莫起风尘叹，犹及清明可到家。  </center></p><hr><h3 id="渔歌子"><a href="#渔歌子" class="headerlink" title="渔歌子"></a><center><strong>渔歌子</strong></center></h3><p><center>作者：魏承班 (唐)</center></p><p><center>柳如眉，云似发，鲛绡雾縠笼香雪。</center></p><p><center>梦魂惊，钟漏歇，窗外晓莺残月。</center></p><p><center><strong><em>几多情，无处说，落花飞絮清明节。</em></strong></center></p><p><center>少年郎，容易别，一去音书断绝。</center></p><hr>]]></content>
    
    <summary type="html">
    
      &lt;h2 id=&quot;一朝春醒-万物清明&quot;&gt;&lt;a href=&quot;#一朝春醒-万物清明&quot; class=&quot;headerlink&quot; title=&quot;一朝春醒 万物清明&quot;&gt;&lt;/a&gt;一朝春醒 万物清明&lt;/h2&gt;&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;iframe frameborder=&quot;no&quot; border=&quot;0&quot; marginwidth=&quot;0&quot; marginheight=&quot;0&quot; width=&quot;330&quot; height=&quot;86&quot; src=&quot;//music.163.com/outchain/player?type=2&amp;id=139377&amp;auto=0&amp;height=66&quot;&gt;&lt;/iframe&gt;&lt;br&gt;&lt;/div&gt; 


&lt;div align=&quot;center&quot;&gt;&lt;br&gt;&lt;a href=&quot;https://imgchr.com/i/CiU5uR&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;&lt;img src=&quot;https://s1.ax1x.com/2018/04/09/CiU5uR.jpg&quot; alt=&quot;CiU5uR.jpg&quot;&gt;&lt;/a&gt;&lt;br&gt;&lt;/div&gt;   

&lt;p&gt;&lt;strong&gt;&lt;em&gt;“万物生长此时，皆清洁明净。故谓之清明。”&lt;/em&gt;&lt;/strong&gt;&lt;br&gt;在我国，很少有一个节日，像清明这样意蕴深厚而含混：风清景明，慎终追远，这是一个悲怆的日子；放歌踏青，追逐春天，这又是一个轻盈的日子。&lt;strong&gt;清明是唯一一个既是节气又是节日的日子。&lt;/strong&gt;  &lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;为测试博客，特此附上有关清明的诗词。&lt;/li&gt;&lt;/ul&gt;
    
    </summary>
    
    
      <category term="清明" scheme="https://zhenfenghan.github.io/tags/%E6%B8%85%E6%98%8E/"/>
    
      <category term="随笔" scheme="https://zhenfenghan.github.io/tags/%E9%9A%8F%E7%AC%94/"/>
    
  </entry>
  
  <entry>
    <title>Will&#39;s First Blog</title>
    <link href="https://zhenfenghan.github.io/2018/04/04/Will-s-first-blog/"/>
    <id>https://zhenfenghan.github.io/2018/04/04/Will-s-first-blog/</id>
    <published>2018-04-04T11:18:47.000Z</published>
    <updated>2018-04-06T14:12:29.531Z</updated>
    
    <content type="html"><![CDATA[<p>这是一篇测试文章，欢迎关注作者博客: <a href="http://willhan.xyz/" target="_blank" rel="noopener">http://willhan.xyz/</a>  或  <a href="https://zhenfenghan.github.io/">https://zhenfenghan.github.io/</a>  <strong>Thank you!</strong> ^_^<br><a id="more"></a><br><strong>Welcome to my little world</strong></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;这是一篇测试文章，欢迎关注作者博客: &lt;a href=&quot;http://willhan.xyz/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;http://willhan.xyz/&lt;/a&gt;  或  &lt;a href=&quot;https://zhenfenghan.github.io/&quot;&gt;https://zhenfenghan.github.io/&lt;/a&gt;  &lt;strong&gt;Thank you!&lt;/strong&gt; ^_^&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="域名" scheme="https://zhenfenghan.github.io/tags/%E5%9F%9F%E5%90%8D/"/>
    
  </entry>
  
  <entry>
    <title>Hello World</title>
    <link href="https://zhenfenghan.github.io/2018/04/04/hello-world/"/>
    <id>https://zhenfenghan.github.io/2018/04/04/hello-world/</id>
    <published>2018-04-04T10:54:02.690Z</published>
    <updated>2018-04-06T14:59:34.784Z</updated>
    
    <content type="html"><![CDATA[<p>Welcome to <a href="https://hexo.io/" target="_blank" rel="noopener">Hexo</a>! This is your very first post. Check <a href="https://hexo.io/docs/" target="_blank" rel="noopener">documentation</a> for more info. If you get any problems when using Hexo, you can find the answer in <a href="https://hexo.io/docs/troubleshooting.html" target="_blank" rel="noopener">troubleshooting</a> or you can ask me on <a href="https://github.com/hexojs/hexo/issues" target="_blank" rel="noopener">GitHub</a>.</p><h2 id="Quick-Start"><a href="#Quick-Start" class="headerlink" title="Quick Start"></a>Quick Start</h2><h3 id="Create-a-new-post"><a href="#Create-a-new-post" class="headerlink" title="Create a new post"></a>Create a new post</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo new <span class="string">"My New Post"</span></span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/writing.html" target="_blank" rel="noopener">Writing</a><br><a id="more"></a></p><h3 id="Run-server"><a href="#Run-server" class="headerlink" title="Run server"></a>Run server</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo server</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/server.html" target="_blank" rel="noopener">Server</a></p><h3 id="Generate-static-files"><a href="#Generate-static-files" class="headerlink" title="Generate static files"></a>Generate static files</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo generate</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/generating.html" target="_blank" rel="noopener">Generating</a></p><h3 id="Deploy-to-remote-sites"><a href="#Deploy-to-remote-sites" class="headerlink" title="Deploy to remote sites"></a>Deploy to remote sites</h3><figure class="highlight bash"><table><tr><td class="gutter"><pre><span class="line">1</span><br></pre></td><td class="code"><pre><span class="line">$ hexo deploy</span><br></pre></td></tr></table></figure><p>More info: <a href="https://hexo.io/docs/deployment.html" target="_blank" rel="noopener">Deployment</a></p>]]></content>
    
    <summary type="html">
    
      &lt;p&gt;Welcome to &lt;a href=&quot;https://hexo.io/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Hexo&lt;/a&gt;! This is your very first post. Check &lt;a href=&quot;https://hexo.io/docs/&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;documentation&lt;/a&gt; for more info. If you get any problems when using Hexo, you can find the answer in &lt;a href=&quot;https://hexo.io/docs/troubleshooting.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;troubleshooting&lt;/a&gt; or you can ask me on &lt;a href=&quot;https://github.com/hexojs/hexo/issues&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;GitHub&lt;/a&gt;.&lt;/p&gt;
&lt;h2 id=&quot;Quick-Start&quot;&gt;&lt;a href=&quot;#Quick-Start&quot; class=&quot;headerlink&quot; title=&quot;Quick Start&quot;&gt;&lt;/a&gt;Quick Start&lt;/h2&gt;&lt;h3 id=&quot;Create-a-new-post&quot;&gt;&lt;a href=&quot;#Create-a-new-post&quot; class=&quot;headerlink&quot; title=&quot;Create a new post&quot;&gt;&lt;/a&gt;Create a new post&lt;/h3&gt;&lt;figure class=&quot;highlight bash&quot;&gt;&lt;table&gt;&lt;tr&gt;&lt;td class=&quot;gutter&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;1&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;td class=&quot;code&quot;&gt;&lt;pre&gt;&lt;span class=&quot;line&quot;&gt;$ hexo new &lt;span class=&quot;string&quot;&gt;&quot;My New Post&quot;&lt;/span&gt;&lt;/span&gt;&lt;br&gt;&lt;/pre&gt;&lt;/td&gt;&lt;/tr&gt;&lt;/table&gt;&lt;/figure&gt;
&lt;p&gt;More info: &lt;a href=&quot;https://hexo.io/docs/writing.html&quot; target=&quot;_blank&quot; rel=&quot;noopener&quot;&gt;Writing&lt;/a&gt;&lt;br&gt;&lt;/p&gt;
    
    </summary>
    
    
      <category term="Hexo" scheme="https://zhenfenghan.github.io/tags/Hexo/"/>
    
  </entry>
  
</feed>
